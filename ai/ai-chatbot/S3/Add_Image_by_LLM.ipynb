{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 17090,
     "status": "ok",
     "timestamp": 1756969626055,
     "user": {
      "displayName": "sr c",
      "userId": "02365314278665536029"
     },
     "user_tz": -540
    },
    "id": "RPJ-VYz-S9fZ",
    "outputId": "a33666c4-07b0-4dd4-c084-bfcba6bc501a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
      "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.101.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.192-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.40.23-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Downloading ultralytics_thop-2.0.17-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
      "Collecting botocore<1.41.0,>=1.40.23 (from boto3)\n",
      "  Downloading botocore-1.40.23-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.14.0,>=0.13.0 (from boto3)\n",
      "  Downloading s3transfer-0.13.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.12/dist-packages (from botocore<1.41.0,>=1.40.23->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.59.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.41.0,>=1.40.23->boto3) (1.17.0)\n",
      "Downloading ultralytics-8.3.192-py3-none-any.whl (1.1 MB)\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m1.1/1.1 MB\u001B[0m \u001B[31m28.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading boto3-1.40.23-py3-none-any.whl (139 kB)\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m139.3/139.3 kB\u001B[0m \u001B[31m11.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading botocore-1.40.23-py3-none-any.whl (14.0 MB)\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m14.0/14.0 MB\u001B[0m \u001B[31m90.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading s3transfer-0.13.1-py3-none-any.whl (85 kB)\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m85.3/85.3 kB\u001B[0m \u001B[31m7.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading ultralytics_thop-2.0.17-py3-none-any.whl (28 kB)\n",
      "Installing collected packages: jmespath, botocore, s3transfer, ultralytics-thop, boto3, ultralytics\n",
      "Successfully installed boto3-1.40.23 botocore-1.40.23 jmespath-1.0.1 s3transfer-0.13.1 ultralytics-8.3.192 ultralytics-thop-2.0.17\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow requests openai tqdm ultralytics torch torchvision torchaudio boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L9ixJrDQbmTH"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from google.colab import userdata\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY_PJ\")\n",
    "os.environ[\"AWS_S3_BUCKET_NAME\"] = userdata.get(\"AWS_S3_BUCKET_NAME\")\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = userdata.get(\"AWS_ACCESS_KEY_ID\")\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = userdata.get(\"AWS_SECRET_ACCESS_KEY\")\n",
    "os.environ[\"AWS_REGION\"] = \"ap-northeast-2\"\n",
    "os.environ[\"S3_FOLDER_PREFIX\"] = \"model_img\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 55,
     "status": "ok",
     "timestamp": 1756970428094,
     "user": {
      "displayName": "sr c",
      "userId": "02365314278665536029"
     },
     "user_tz": -540
    },
    "id": "hWoC-OhfW47W",
    "outputId": "a907a36b-81f9-402b-d114-c5f31b026709"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… s3_uploader.py ëª¨ë“ˆì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "s3_uploader_code = '''\n",
    "\"\"\"\n",
    "s3_uploader.py\n",
    "Virtual Try-on ê²°ê³¼ ì´ë¯¸ì§€ë¥¼ S3ì— ì—…ë¡œë“œí•˜ê³  URLì„ ë°˜í™˜í•˜ëŠ” ëª¨ë“ˆ\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import io\n",
    "import boto3\n",
    "from pathlib import Path\n",
    "from typing import Optional, Union\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "from botocore.exceptions import ClientError, NoCredentialsError\n",
    "\n",
    "\n",
    "class S3ImageUploader:\n",
    "    \"\"\"S3ì— ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ê³  URLì„ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        bucket_name: str,\n",
    "        aws_access_key_id: Optional[str] = None,\n",
    "        aws_secret_access_key: Optional[str] = None,\n",
    "        region_name: str = 'ap-northeast-2',\n",
    "        folder_prefix: str = 'tryon-images'\n",
    "    ):\n",
    "        \"\"\"S3 ì—…ë¡œë” ì´ˆê¸°í™”\"\"\"\n",
    "        self.bucket_name = bucket_name\n",
    "        self.folder_prefix = folder_prefix.strip('/')\n",
    "\n",
    "        try:\n",
    "            if aws_access_key_id and aws_secret_access_key:\n",
    "                self.s3_client = boto3.client(\n",
    "                    's3',\n",
    "                    aws_access_key_id=aws_access_key_id,\n",
    "                    aws_secret_access_key=aws_secret_access_key,\n",
    "                    region_name=region_name\n",
    "                )\n",
    "            else:\n",
    "                self.s3_client = boto3.client('s3', region_name=region_name)\n",
    "\n",
    "            # ë²„í‚· ì ‘ê·¼ ê¶Œí•œ í™•ì¸\n",
    "            self.s3_client.head_bucket(Bucket=bucket_name)\n",
    "\n",
    "        except NoCredentialsError:\n",
    "            raise ValueError(\"AWS ìê²© ì¦ëª…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        except ClientError as e:\n",
    "            error_code = e.response['Error']['Code']\n",
    "            if error_code == '403':\n",
    "                raise ValueError(f\"S3 ë²„í‚· '{bucket_name}'ì— ëŒ€í•œ ì•¡ì„¸ìŠ¤ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            elif error_code == '404':\n",
    "                raise ValueError(f\"S3 ë²„í‚· '{bucket_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            else:\n",
    "                raise ValueError(f\"S3 ì—°ê²° ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "    def _generate_filename(self, product_id: str, extension: str = 'png') -> str:\n",
    "        \"\"\"ê³ ìœ í•œ íŒŒì¼ëª… ìƒì„±\"\"\"\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        unique_id = str(uuid.uuid4())[:8]\n",
    "        return f\"{self.folder_prefix}/{timestamp}/{product_id}_{unique_id}.{extension}\"\n",
    "\n",
    "    def upload_file(self, file_path: Union[str, Path], product_id: str) -> str:\n",
    "        \"\"\"\n",
    "        ë¡œì»¬ íŒŒì¼ì„ S3ì— ì—…ë¡œë“œí•˜ê³  ê³µê°œ URL ë°˜í™˜\n",
    "\n",
    "        Args:\n",
    "            file_path: ì—…ë¡œë“œí•  íŒŒì¼ ê²½ë¡œ\n",
    "            product_id: ì œí’ˆ ID\n",
    "\n",
    "        Returns:\n",
    "            S3 ê³µê°œ URL\n",
    "        \"\"\"\n",
    "        file_path = Path(file_path)\n",
    "        if not file_path.exists():\n",
    "            raise FileNotFoundError(f\"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}\")\n",
    "\n",
    "        extension = file_path.suffix.lstrip('.')\n",
    "        s3_key = self._generate_filename(product_id, extension)\n",
    "\n",
    "        try:\n",
    "            self.s3_client.upload_file(\n",
    "                str(file_path),\n",
    "                self.bucket_name,\n",
    "                s3_key,\n",
    "                ExtraArgs={\n",
    "                    'ContentType': 'image/png' if extension.lower() == 'png' else 'image/jpeg',\n",
    "                    'ACL': 'public-read'\n",
    "                }\n",
    "            )\n",
    "\n",
    "            return f\"https://{self.bucket_name}.s3.amazonaws.com/{s3_key}\"\n",
    "\n",
    "        except ClientError as e:\n",
    "            raise RuntimeError(f\"S3 ì—…ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "\n",
    "def setup_s3_uploader() -> S3ImageUploader:\n",
    "    \"\"\"í™˜ê²½ë³€ìˆ˜ì—ì„œ ì„¤ì •ì„ ì½ì–´ S3 ì—…ë¡œë” ìƒì„±\"\"\"\n",
    "    bucket_name = os.getenv('AWS_S3_BUCKET_NAME')\n",
    "    if not bucket_name:\n",
    "        raise ValueError(\"í™˜ê²½ë³€ìˆ˜ AWS_S3_BUCKET_NAMEì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    return S3ImageUploader(\n",
    "        bucket_name=bucket_name,\n",
    "        aws_access_key_id=os.getenv('AWS_ACCESS_KEY_ID'),\n",
    "        aws_secret_access_key=os.getenv('AWS_SECRET_ACCESS_KEY'),\n",
    "        region_name=os.getenv('AWS_REGION', 'ap-northeast-2'),\n",
    "        folder_prefix=os.getenv('S3_FOLDER_PREFIX', 'tryon-results')\n",
    "    )\n",
    "'''\n",
    "\n",
    "# íŒŒì¼ë¡œ ì €ì¥\n",
    "with open('s3_uploader.py', 'w', encoding='utf-8') as f:\n",
    "    f.write(s3_uploader_code)\n",
    "\n",
    "print(\"âœ… s3_uploader.py ëª¨ë“ˆì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 419,
     "status": "ok",
     "timestamp": 1756970645171,
     "user": {
      "displayName": "sr c",
      "userId": "02365314278665536029"
     },
     "user_tz": -540
    },
    "id": "6gqgm1f_W47W",
    "outputId": "3ec27621-5001-41b7-f346-34824e40d4f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… S3 ì—…ë¡œë” ì´ˆê¸°í™” ì™„ë£Œ\n",
      "   ë²„í‚·: elasticbeanstalk-ap-northeast-2-967883357924\n",
      "   í´ë”: model_img\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from openai import OpenAI\n",
    "\n",
    "# Python ê²½ë¡œì— í˜„ì¬ ë””ë ‰í† ë¦¬ ì¶”ê°€\n",
    "if '.' not in sys.path:\n",
    "    sys.path.append('.')\n",
    "\n",
    "# ê¸°ì¡´ ëª¨ë“ˆ ìºì‹œ ì‚­ì œ\n",
    "if 's3_uploader' in sys.modules:\n",
    "    del sys.modules['s3_uploader']\n",
    "\n",
    "# ========= ì‚¬ìš©ì ì„¤ì • =========\n",
    "APP_JSON    = Path(\"app_product.json\")   # ì œí’ˆ ë¦¬ìŠ¤íŠ¸\n",
    "OUT_DIR     = Path(\"out/tryon_openai\")\n",
    "MODEL_NAME  = \"gpt-image-1\"              # OpenAI ì´ë¯¸ì§€ í¸ì§‘ ëª¨ë¸\n",
    "\n",
    "# ì´ë²ˆ ì‹¤í–‰ì—ì„œ ì²˜ë¦¬í•  idë“¤\n",
    "SELECTED_IDS = [641]\n",
    "\n",
    "# ìº”ë²„ìŠ¤(ì¢Œ: ëª¨ë¸ / ìš°: ì˜ë¥˜ ì°¸ê³ )\n",
    "SIZE      = (1536, 1024)   # (W, H)\n",
    "LEFT_BOX  = (0, 0, 768, 1024)\n",
    "RIGHT_BOX = (768, 0, 1536, 1024)\n",
    "\n",
    "# ì¹´í…Œê³ ë¦¬ë³„ ê¸°ë³¸ ë§ˆìŠ¤í¬ ë¹„ìœ¨(LEFT_BOX ê¸°ì¤€)\n",
    "CATEGORY_MASK_RATIOS = {\n",
    "    \"upper\":     (0.18, 0.18, 0.82, 0.64),\n",
    "    \"lower\":     (0.22, 0.55, 0.78, 0.95),\n",
    "    \"outer\":     (0.12, 0.12, 0.88, 0.85),\n",
    "    \"onepiece\":  (0.18, 0.18, 0.82, 0.90),\n",
    "    \"full\":      (0.10, 0.06, 0.90, 0.95),\n",
    "}\n",
    "MASK_FEATHER = 16\n",
    "\n",
    "# ë¡œì»¬ GPUë¡œ ìë™ ë§ˆìŠ¤í¬(ì„¸ê·¸ë©˜í…Œì´ì…˜+í¬ì¦ˆ) ì‚¬ìš©\n",
    "USE_LOCAL_GPU_MASK = True\n",
    "USE_POSE_LANDMARKS = True\n",
    "YOLO_SEG_MODEL     = \"yolov8n-seg.pt\"\n",
    "YOLO_POSE_MODEL    = \"yolov8n-pose.pt\"\n",
    "MIN_CONF_KEYPT     = 0.35\n",
    "\n",
    "# S3 ì—…ë¡œë“œ ì„¤ì •\n",
    "USE_S3_UPLOAD = True\n",
    "\n",
    "# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”\n",
    "client = OpenAI()\n",
    "\n",
    "# S3 ì—…ë¡œë” ì´ˆê¸°í™”\n",
    "s3_uploader = None\n",
    "if USE_S3_UPLOAD:\n",
    "    try:\n",
    "        from s3_uploader import setup_s3_uploader\n",
    "        s3_uploader = setup_s3_uploader()\n",
    "        print(f\"âœ… S3 ì—…ë¡œë” ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "        print(f\"   ë²„í‚·: {s3_uploader.bucket_name}\")\n",
    "        print(f\"   í´ë”: {s3_uploader.folder_prefix}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ S3 ì—…ë¡œë” ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "        USE_S3_UPLOAD = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "executionInfo": {
     "elapsed": 57,
     "status": "error",
     "timestamp": 1758096075638,
     "user": {
      "displayName": "Jh K",
      "userId": "12877179054230177413"
     },
     "user_tz": -540
    },
    "id": "ROe66uDrMHyi",
    "outputId": "55386a74-81f4-4a50-dfb6-03789d2092d7"
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEY í•„ìš”",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipython-input-3203520146.py\u001B[0m in \u001B[0;36m<cell line: 0>\u001B[0;34m()\u001B[0m\n\u001B[1;32m    365\u001B[0m \u001B[0;31m# =============================================================================\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    366\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0m__name__\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"__main__\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 367\u001B[0;31m     \u001B[0mmain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/tmp/ipython-input-3203520146.py\u001B[0m in \u001B[0;36mmain\u001B[0;34m()\u001B[0m\n\u001B[1;32m    316\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mmain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    317\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgetenv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"OPENAI_API_KEY\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 318\u001B[0;31m         \u001B[0;32mraise\u001B[0m \u001B[0mRuntimeError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEY í•„ìš”\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    319\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    320\u001B[0m     \u001B[0;31m# GPU ë„êµ¬ í™•ì¸(ì—†ìœ¼ë©´ ìë™ ë¹„í™œì„±í™”)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEY í•„ìš”"
     ]
    }
   ],
   "source": [
    "# file: tryon_ids_openai.py\n",
    "import base64\n",
    "from pathlib import Path\n",
    "from typing import List, Any, Optional\n",
    "from PIL import Image, ImageOps, ImageDraw, ImageChops\n",
    "from openai import OpenAI\n",
    "from datetime import datetime\n",
    "\n",
    "def ensure_list(x):\n",
    "    if x is None: return []\n",
    "    return x if isinstance(x, list) else [x]\n",
    "\n",
    "def download_image(url: str) -> Image.Image:\n",
    "    r = requests.get(url, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    return Image.open(io.BytesIO(r.content)).convert(\"RGBA\")\n",
    "\n",
    "def download_bytes(url: str) -> bytes:\n",
    "    r = requests.get(url, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    return r.content\n",
    "\n",
    "def fit_into(img: Image.Image, box: tuple, keep_aspect=True, pad_color=(255,255,255,0)) -> Image.Image:\n",
    "    x1,y1,x2,y2 = box\n",
    "    w, h = x2-x1, y2-y1\n",
    "    if keep_aspect:\n",
    "        img = ImageOps.contain(img, (w,h))\n",
    "        canvas = Image.new(\"RGBA\", (w,h), pad_color)\n",
    "        canvas.paste(img, ((w - img.width)//2, (h - img.height)//2), img)\n",
    "        return canvas\n",
    "    return img.resize((w,h), Image.LANCZOS)\n",
    "\n",
    "def make_collage(model_img: Image.Image, garments: List[Image.Image]) -> Image.Image:\n",
    "    W,H = SIZE\n",
    "    canvas = Image.new(\"RGBA\", (W,H), (255,255,255,255))\n",
    "    left_fitted = fit_into(model_img, LEFT_BOX)\n",
    "    canvas.paste(left_fitted, (LEFT_BOX[0], LEFT_BOX[1]), left_fitted)\n",
    "\n",
    "    rows = max(1, min(2, len(garments)))\n",
    "    each_h = (RIGHT_BOX[3] - RIGHT_BOX[1]) // rows\n",
    "    for i, g in enumerate(garments[:rows], 0):\n",
    "        slot = (RIGHT_BOX[0], RIGHT_BOX[1] + i*each_h, RIGHT_BOX[2], RIGHT_BOX[1] + (i+1)*each_h)\n",
    "        fitted = fit_into(g, slot)\n",
    "        canvas.paste(fitted, (slot[0], slot[1]), fitted)\n",
    "    return canvas\n",
    "\n",
    "def _feather(mask: Image.Image, radius: int) -> Image.Image:\n",
    "    if radius <= 0: return mask\n",
    "    small = mask.resize((max(1,mask.width//4), max(1,mask.height//4)), Image.BILINEAR)\n",
    "    return small.resize(mask.size, Image.BILINEAR)\n",
    "\n",
    "# =============================================================================\n",
    "# 6. GPU ë§ˆìŠ¤í¬ ë° í¬ì¦ˆ ê´€ë ¨ í•¨ìˆ˜ë“¤\n",
    "# =============================================================================\n",
    "def _person_mask_yolov8(model_img_rgba: Image.Image) -> Optional[Image.Image]:\n",
    "    try:\n",
    "        from ultralytics import YOLO\n",
    "        import torch\n",
    "    except Exception:\n",
    "        return None\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = YOLO(YOLO_SEG_MODEL)\n",
    "    crop = model_img_rgba.crop(LEFT_BOX).convert(\"RGB\")\n",
    "    results = model.predict(crop, imgsz=768, conf=0.25, device=device, verbose=False)\n",
    "    if not results or len(results[0].masks or []) == 0:\n",
    "        return None\n",
    "    import numpy as np\n",
    "    m = Image.new(\"L\", crop.size, 0)\n",
    "    for j, cls in enumerate(results[0].boxes.cls.tolist()):\n",
    "        if int(cls) == 0 and results[0].masks is not None:  # person class\n",
    "            mask_arr = results[0].masks.data[j].cpu().numpy()\n",
    "            mask_img = Image.fromarray((mask_arr*255).astype(\"uint8\"), mode=\"L\")\n",
    "            m = ImageChops.lighter(m, mask_img)\n",
    "    full = Image.new(\"L\", SIZE, 0)\n",
    "    full.paste(m, (LEFT_BOX[0], LEFT_BOX[1]))\n",
    "    return full\n",
    "\n",
    "def _pose_keypoints_yolo(model_img_rgba: Image.Image) -> Optional[dict]:\n",
    "    try:\n",
    "        from ultralytics import YOLO\n",
    "        import torch, numpy as np\n",
    "    except Exception:\n",
    "        return None\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    crop = model_img_rgba.crop(LEFT_BOX).convert(\"RGB\")\n",
    "    model = YOLO(YOLO_POSE_MODEL)\n",
    "    res = model.predict(crop, imgsz=768, device=device, conf=0.25, verbose=False)\n",
    "    if not res:\n",
    "        return None\n",
    "    r = res[0]\n",
    "    if r.keypoints is None or r.boxes is None or len(r.keypoints) == 0:\n",
    "        return None\n",
    "\n",
    "    areas = (r.boxes.xyxy[:,2]-r.boxes.xyxy[:,0]) * (r.boxes.xyxy[:,3]-r.boxes.xyxy[:,1])\n",
    "    idx = int((areas).argmax())\n",
    "    kpts = r.keypoints.xy[idx].cpu().numpy()  # (17,2)\n",
    "    conf = r.keypoints.conf[idx].cpu().numpy() if r.keypoints.conf is not None else __import__(\"numpy\").ones((kpts.shape[0],))\n",
    "\n",
    "    KP = {\"L_SHOULDER\":5,\"R_SHOULDER\":6,\"L_HIP\":11,\"R_HIP\":12,\"L_KNEE\":13,\"R_KNEE\":14,\"L_ANKLE\":15,\"R_ANKLE\":16}\n",
    "    def y_of(a,b):\n",
    "        ys=[]\n",
    "        for i in (a,b):\n",
    "            if i < len(kpts) and conf[i] >= MIN_CONF_KEYPT: ys.append(kpts[i][1])\n",
    "        return int(__import__(\"numpy\").mean(ys)) if ys else None\n",
    "\n",
    "    y_sh = y_of(KP[\"L_SHOULDER\"], KP[\"R_SHOULDER\"])\n",
    "    y_hp = y_of(KP[\"L_HIP\"],      KP[\"R_HIP\"])\n",
    "    y_kn = y_of(KP[\"L_KNEE\"],     KP[\"R_KNEE\"])\n",
    "    y_an = y_of(KP[\"L_ANKLE\"],    KP[\"R_ANKLE\"])\n",
    "\n",
    "    x1,y1,x2,y2 = r.boxes.xyxy[idx].cpu().numpy().astype(int).tolist()\n",
    "    x1 += LEFT_BOX[0]; x2 += LEFT_BOX[0]\n",
    "    y1 += LEFT_BOX[1]; y2 += LEFT_BOX[1]\n",
    "\n",
    "    def to_full_y(y): return int(y + LEFT_BOX[1]) if y is not None else None\n",
    "    return {\"shoulders_y\":to_full_y(y_sh),\"hips_y\":to_full_y(y_hp),\"knees_y\":to_full_y(y_kn),\"ankles_y\":to_full_y(y_an),\"bbox\":(x1,y1,x2,y2)}\n",
    "\n",
    "def make_mask(category: str, base_img: Image.Image) -> Image.Image:\n",
    "    mask = Image.new(\"L\", SIZE, 0)\n",
    "    draw = ImageDraw.Draw(mask)\n",
    "\n",
    "    dyn = _pose_keypoints_yolo(base_img) if USE_POSE_LANDMARKS else None\n",
    "    def rect(x1,y1,x2,y2): draw.rectangle((int(x1),int(y1),int(x2),int(y2)), fill=255)\n",
    "\n",
    "    if dyn:\n",
    "        x1,y1,x2,y2 = dyn[\"bbox\"]\n",
    "        pad_x = int((x2-x1)*0.08); pad_y = int((y2-y1)*0.05)\n",
    "        sh = dyn[\"shoulders_y\"] or (LEFT_BOX[1] + int((LEFT_BOX[3]-LEFT_BOX[1])*0.22))\n",
    "        hp = dyn[\"hips_y\"]      or (LEFT_BOX[1] + int((LEFT_BOX[3]-LEFT_BOX[1])*0.58))\n",
    "        kn = dyn[\"knees_y\"]     or (LEFT_BOX[1] + int((LEFT_BOX[3]-LEFT_BOX[1])*0.80))\n",
    "        an = dyn[\"ankles_y\"]    or (LEFT_BOX[1] + int((LEFT_BOX[3]-LEFT_BOX[1])*0.95))\n",
    "\n",
    "        cat = (category or \"upper\").lower()\n",
    "        if cat == \"upper\":\n",
    "            rect(max(LEFT_BOX[0], x1+pad_x), max(LEFT_BOX[1], sh - (hp-sh)*0.2),\n",
    "                 min(LEFT_BOX[2], x2-pad_x), min(LEFT_BOX[3], hp + (hp-sh)*0.05))\n",
    "        elif cat == \"lower\":\n",
    "            rect(max(LEFT_BOX[0], x1+pad_x), max(LEFT_BOX[1], hp - (hp-sh)*0.05),\n",
    "                 min(LEFT_BOX[2], x2-pad_x), min(LEFT_BOX[3], an))\n",
    "        elif cat == \"outer\":\n",
    "            rect(max(LEFT_BOX[0], x1+int(pad_x*0.7)), max(LEFT_BOX[1], sh - (hp-sh)*0.6),\n",
    "                 min(LEFT_BOX[2], x2-int(pad_x*0.7)), min(LEFT_BOX[3], kn))\n",
    "        elif cat in (\"onepiece\",\"dress\"):\n",
    "            rect(max(LEFT_BOX[0], x1+pad_x), max(LEFT_BOX[1], sh - (hp-sh)*0.2),\n",
    "                 min(LEFT_BOX[2], x2-pad_x), min(LEFT_BOX[3], max(kn, hp + (hp-sh))))\n",
    "        else:  # full\n",
    "            rect(max(LEFT_BOX[0], x1+pad_x), max(LEFT_BOX[1], y1+pad_y),\n",
    "                 min(LEFT_BOX[2], x2-pad_x), min(LEFT_BOX[3], an))\n",
    "    else:\n",
    "        rx1,ry1,rx2,ry2 = CATEGORY_MASK_RATIOS.get((category or \"upper\").lower(), CATEGORY_MASK_RATIOS[\"upper\"])\n",
    "        lx1,ly1,lx2,ly2 = LEFT_BOX\n",
    "        rect(lx1 + (lx2-lx1)*rx1, ly1 + (ly2-ly1)*ry1, lx1 + (lx2-lx1)*rx2, ly1 + (ly2-ly1)*ry2)\n",
    "\n",
    "    if USE_LOCAL_GPU_MASK:\n",
    "        person = _person_mask_yolov8(base_img)\n",
    "        if person is not None:\n",
    "            mask = ImageChops.multiply(mask, person)\n",
    "\n",
    "    return _feather(mask, MASK_FEATHER)\n",
    "\n",
    "# =============================================================================\n",
    "# 7. OpenAI ì´ë¯¸ì§€ í¸ì§‘ + S3 ì—…ë¡œë“œ í•¨ìˆ˜\n",
    "# =============================================================================\n",
    "def call_openai_edit(base_img, mask_img, prompt, out_path):\n",
    "    \"\"\"OpenAI ì´ë¯¸ì§€ í¸ì§‘ + S3 ì—…ë¡œë“œ\"\"\"\n",
    "    # 1) ë§ˆìŠ¤í¬ë¥¼ RGBAë¡œ ë§Œë“¤ê³ , ì•ŒíŒŒ ì±„ë„ì— ë§ˆìŠ¤í¬ë¥¼ ë³µì‚¬\n",
    "    mask_L = mask_img.convert(\"L\")\n",
    "    mask_rgba = mask_L.convert(\"RGBA\")\n",
    "    mask_rgba.putalpha(mask_L)\n",
    "\n",
    "    # 2) BytesIOì— ì €ì¥ + name ë¶€ì—¬\n",
    "    base_buf = io.BytesIO()\n",
    "    base_img.save(base_buf, format=\"PNG\")\n",
    "    base_buf.seek(0)\n",
    "    base_buf.name = \"base.png\"\n",
    "\n",
    "    mask_buf = io.BytesIO()\n",
    "    mask_rgba.save(mask_buf, format=\"PNG\")\n",
    "    mask_buf.seek(0)\n",
    "    mask_buf.name = \"mask.png\"\n",
    "\n",
    "    # 3) OpenAI API í˜¸ì¶œ\n",
    "    resp = client.images.edit(\n",
    "        model=MODEL_NAME,\n",
    "        image=base_buf,\n",
    "        mask=mask_buf,\n",
    "        prompt=prompt,\n",
    "        size=\"1024x1024\",\n",
    "        n=1,\n",
    "    )\n",
    "\n",
    "    # 4) ë¡œì»¬ ì €ì¥\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    b64 = resp.data[0].b64_json\n",
    "    out_path.write_bytes(base64.b64decode(b64))\n",
    "    print(f\"ğŸ’¾ ë¡œì»¬ ì €ì¥ ì™„ë£Œ: {out_path}\")\n",
    "\n",
    "    # 5) S3 ì—…ë¡œë“œ\n",
    "    if USE_S3_UPLOAD and s3_uploader:\n",
    "        try:\n",
    "            product_id = out_path.stem.split('_')[0]\n",
    "            s3_url = s3_uploader.upload_file(out_path, product_id)\n",
    "            print(f\"ğŸ“¤ S3 ì—…ë¡œë“œ ì™„ë£Œ: {s3_url}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ S3 ì—…ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "    return str(out_path)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 8. ëª¨ë¸ ë° ì œí’ˆ ë°ì´í„° ë¡œë”© í•¨ìˆ˜ë“¤\n",
    "# =============================================================================\n",
    "def load_models_by_gender(path: Path) -> dict:\n",
    "    \"\"\"model_list.jsonì„ ë¡œë“œí•´ ì„±ë³„ë³„ ëŒ€í‘œ ì´ë¯¸ì§€ URL ë”•ì…”ë„ˆë¦¬ë¡œ ì •ê·œí™”\"\"\"\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"ëª¨ë¸ JSON ì—†ìŒ: {path}\")\n",
    "\n",
    "    raw = path.read_text(encoding=\"utf-8\").strip()\n",
    "    try:\n",
    "        obj = json.loads(raw)\n",
    "    except json.JSONDecodeError:\n",
    "        obj = [json.loads(l) for l in raw.splitlines() if l.strip()]\n",
    "\n",
    "    db = {}\n",
    "\n",
    "    def _norm_gender(g: str) -> str | None:\n",
    "        g = (g or \"\").strip().lower()\n",
    "        if g in (\"female\",\"f\",\"ì—¬\",\"ì—¬ì\",\"woman\",\"girl\",\"w\"): return \"female\"\n",
    "        if g in (\"male\",\"m\",\"ë‚¨\",\"ë‚¨ì\",\"man\",\"boy\"):         return \"male\"\n",
    "        if g in (\"default\",\"any\",\"*\"):                        return \"default\"\n",
    "        return None\n",
    "\n",
    "    def _extract_url(v) -> str | None:\n",
    "        if isinstance(v, dict):\n",
    "            return v.get(\"model_url\") or v.get(\"image_url\")\n",
    "        if isinstance(v, str):\n",
    "            return v\n",
    "        return None\n",
    "\n",
    "    if isinstance(obj, dict):\n",
    "        for g, v in obj.items():\n",
    "            key = _norm_gender(g)\n",
    "            url = _extract_url(v)\n",
    "            if key and url:\n",
    "                db[key] = url\n",
    "    else:\n",
    "        for it in obj:\n",
    "            key = _norm_gender(it.get(\"gender\"))\n",
    "            url = it.get(\"model_url\") or it.get(\"image_url\")\n",
    "            if key and url:\n",
    "                db[key] = url\n",
    "\n",
    "    return db\n",
    "\n",
    "def resolve_model_url_by_gender(item: dict, models_by_gender: dict) -> Optional[str]:\n",
    "    g = str(item.get(\"gender\") or item.get(\"model_gender\") or \"\").strip().lower()\n",
    "    key = \"female\" if g in (\"female\",\"f\",\"ì—¬\",\"ì—¬ì\",\"woman\",\"girl\",\"w\") else \"male\" if g in (\"male\",\"m\",\"ë‚¨\",\"ë‚¨ì\",\"man\",\"boy\") else None\n",
    "    if key and key in models_by_gender: return models_by_gender[key]\n",
    "    if \"default\" in models_by_gender:   return models_by_gender[\"default\"]\n",
    "    return models_by_gender.get(\"female\") or models_by_gender.get(\"male\")\n",
    "\n",
    "def load_items_by_ids(path: Path, selected_ids: List[Any]) -> List[dict]:\n",
    "    raw = path.read_text(encoding=\"utf-8\")\n",
    "    try:\n",
    "        data = json.loads(raw)\n",
    "        if isinstance(data, dict): data = [data]\n",
    "    except json.JSONDecodeError:\n",
    "        data = [json.loads(l) for l in raw.splitlines() if l.strip()]\n",
    "    sids = {str(x) for x in (selected_ids or [])}\n",
    "    picked = [it for it in data if str(it.get(\"id\") or it.get(\"external_id\")) in sids]\n",
    "    if not picked:\n",
    "        raise ValueError(f\"id {sorted(sids)} í•­ëª©ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\")\n",
    "    return picked\n",
    "\n",
    "# =============================================================================\n",
    "# 9. ê²°ê³¼ í™•ì¸ í•¨ìˆ˜ë“¤\n",
    "# =============================================================================\n",
    "def get_s3_urls_from_results(results_dir=\"out/tryon_openai\"):\n",
    "    \"\"\"ìƒì„±ëœ ê²°ê³¼ì—ì„œ S3 URLë“¤ì„ ìˆ˜ì§‘\"\"\"\n",
    "    results_dir = Path(results_dir)\n",
    "    s3_urls = {}\n",
    "\n",
    "    for info_file in results_dir.glob(\"*_info.json\"):\n",
    "        try:\n",
    "            data = json.loads(info_file.read_text())\n",
    "            product_id = data.get(\"product_id\")\n",
    "            s3_url = data.get(\"s3_url\")\n",
    "\n",
    "            if product_id and s3_url:\n",
    "                s3_urls[product_id] = {\n",
    "                    \"url\": s3_url,\n",
    "                    \"folder\": data.get(\"s3_folder\"),\n",
    "                    \"local_path\": data.get(\"local_path\"),\n",
    "                    \"timestamp\": data.get(\"timestamp\")\n",
    "                }\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return s3_urls\n",
    "\n",
    "\n",
    "def main():\n",
    "    if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "        raise RuntimeError(\"í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEY í•„ìš”\")\n",
    "\n",
    "    # GPU ë„êµ¬ í™•ì¸(ì—†ìœ¼ë©´ ìë™ ë¹„í™œì„±í™”)\n",
    "    if USE_LOCAL_GPU_MASK or USE_POSE_LANDMARKS:\n",
    "        try:\n",
    "            import torch, ultralytics  # noqa\n",
    "        except Exception as e:\n",
    "            print(f\"[ê²½ê³ ] ë¡œì»¬ GPU ë§ˆìŠ¤í¬/í¬ì¦ˆ ë¹„í™œì„±í™”: {e}\")\n",
    "            globals()[\"USE_LOCAL_GPU_MASK\"] = False\n",
    "            globals()[\"USE_POSE_LANDMARKS\"] = False\n",
    "\n",
    "    # ì œí’ˆ ë°ì´í„° ë¡œë“œ (ì‹¤ì œ URLì€ ë¬´ì‹œ)\n",
    "    items = load_items_by_ids(APP_JSON, SELECTED_IDS)\n",
    "    OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for item in items:\n",
    "        pid = item.get(\"id\") or item.get(\"external_id\")\n",
    "\n",
    "        # ì‹¤ì œ garment_urls ë¬´ì‹œ â†’ ë”ë¯¸ ì´ë¯¸ì§€ 2ê°œ ìƒì„±\n",
    "        garments = []\n",
    "        for i, color in enumerate([\"red\", \"blue\"]):\n",
    "            g = Image.new(\"RGBA\", (512, 512), color=color)\n",
    "            garments.append(g)\n",
    "\n",
    "        # ëª¨ë¸ ì´ë¯¸ì§€ë„ ë”ë¯¸ ìƒì„± (ë…¹ìƒ‰)\n",
    "        model_img = Image.new(\"RGBA\", (512, 1024), color=\"green\")\n",
    "\n",
    "        # ì½œë¼ì£¼ & ë§ˆìŠ¤í¬\n",
    "        collage  = make_collage(model_img, garments)\n",
    "        category = str(item.get(\"category\") or \"upper\").lower()\n",
    "        mask_img = make_mask(category, collage)\n",
    "\n",
    "        # í”„ë¡¬í”„íŠ¸ (ë”ë¯¸)\n",
    "        prompt = \"ì™¼ìª½ ì‚¬ëŒì— ë…¹ìƒ‰ ì˜·ì„ ì…íˆê³  ì˜¤ë¥¸ìª½ ì˜ë¥˜(ë¹¨ê°•, íŒŒë‘)ë¥¼ ì°¸ì¡°í•˜ì—¬ ì°©ì¥ì²˜ëŸ¼ ë³´ì´ê²Œ\"\n",
    "\n",
    "        # ìƒì„± â†’ ì´ë¯¸ì§€ íŒŒì¼ ì €ì¥ + S3 ì—…ë¡œë“œ\n",
    "        out_path = OUT_DIR / f\"{pid}_tryon.png\"\n",
    "        try:\n",
    "            saved = call_openai_edit(collage, mask_img, prompt, out_path)\n",
    "            print(f\"[OK] id={pid} â†’ {saved}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] id={pid} í¸ì§‘ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 11. ì‹¤í–‰\n",
    "# =============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# file: tryon_looks_sdxl_s3_colab.py\n",
    "import os, io, json, re, datetime, asyncio, time, requests\n",
    "from pathlib import Path\n",
    "from typing import List, Any, Dict, Optional\n",
    "from PIL import Image\n",
    "from zoneinfo import ZoneInfo\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import torch\n",
    "from diffusers import StableDiffusionControlNetPipeline, ControlNetModel\n",
    "import cv2, numpy as np\n",
    "\n",
    "# Colab/Jupyter ì´ë²¤íŠ¸ ë£¨í”„ ì¶©ëŒ ë°©ì§€\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from huggingface_hub import login\n",
    "login(os.getenv(\"HF_TOKEN\"))  # ë˜ëŠ” ì§ì ‘ ë¬¸ìì—´ í† í° ì…ë ¥\n",
    "\n",
    "\n",
    "# =========================\n",
    "# í™˜ê²½ë³€ìˆ˜\n",
    "# =========================\n",
    "SIZE_W, SIZE_H = 512, 512\n",
    "MAX_REFS = 6\n",
    "LOOKS_JSON = Path(os.getenv(\"LOOKS_JSON_PATH\", \"S3/app_product_test.json\"))\n",
    "\n",
    "AWS_S3_BUCKET  = os.getenv(\"AWS_S3_BUCKET_NAME\")\n",
    "AWS_REGION     = os.getenv(\"AWS_S3_REGION\", \"ap-northeast-2\")\n",
    "AWS_S3_PREFIX  = os.getenv(\"AWS_S3_PREFIX\", \"tryon\")\n",
    "\n",
    "# ===== ëª¨ë¸ ì¡°í•© =====\n",
    "# HF í† í°ìœ¼ë¡œ ì ‘ê·¼ ìŠ¹ì¸ ë°›ì€ SDXL baseë¥¼ ì“°ë ¤ë©´ ì•„ë˜ ë¼ì¸ ì‚¬ìš©\n",
    "BASE_MODEL = \"stabilityai/stable-diffusion-xl-base-1.0\"   # (gated) ë¡œê·¸ì¸ í•„ìš”\n",
    "CONTROL_MODEL = \"lllyasviel/sd-controlnet-canny\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ===== íŒŒì´í”„ë¼ì¸ ë¡œë“œ (1íšŒ) =====\n",
    "controlnet = ControlNetModel.from_pretrained(\n",
    "    CONTROL_MODEL,\n",
    "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
    ")\n",
    "pipe = StableDiffusionControlNetPipeline.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    controlnet=controlnet,\n",
    "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
    "    # safety_checker=None  # âŒ ë°°í¬ìš© ì•„ë‹˜: ê¸°ë³¸ê°’ ìœ ì§€(ê²½ê³  ì•ˆ ëœ¨ê²Œ)\n",
    ").to(device)\n",
    "\n",
    "# ---------- JSON â†’ ë£© ì •ê·œí™” ----------\n",
    "KNOWN_PART_KEYS = [\"top\",\"bottom\",\"outer\",\"onepiece\",\"dress\",\"bag\",\"shoes\",\"acc\",\"accessory\"]\n",
    "\n",
    "def normalize_look(look: Dict) -> Dict:\n",
    "    garment_urls: List[str] = []\n",
    "    ref_ids: List[str] = []\n",
    "    def add_part(part: Any):\n",
    "        if not isinstance(part, dict): return\n",
    "        url = part.get(\"image_url\")\n",
    "        pid = part.get(\"search_history_product_id\")\n",
    "        if url: garment_urls.append(url)\n",
    "        if pid is not None: ref_ids.append(str(pid))\n",
    "\n",
    "    for k in KNOWN_PART_KEYS:\n",
    "        if k in look:\n",
    "            v = look[k]\n",
    "            if isinstance(v, list):\n",
    "                for it in v: add_part(it)\n",
    "            else:\n",
    "                add_part(v)\n",
    "    raw_look_id = look.get(\"look_id\") or look.get(\"id\") or \"_\".join(ref_ids) or \"look\"\n",
    "    return {\n",
    "        \"look_id\": str(raw_look_id),\n",
    "        \"garment_urls\": garment_urls[:MAX_REFS],\n",
    "        \"ref_ids\": ref_ids,\n",
    "        \"meta\": {\"look_style\": look.get(\"look_style\")}\n",
    "    }\n",
    "\n",
    "def load_all_looks(path: Path) -> List[Dict]:\n",
    "    obj = json.loads(path.read_text(encoding=\"utf-8\"))\n",
    "    if isinstance(obj, dict) and isinstance(obj.get(\"results\"), list):\n",
    "        data = obj[\"results\"]\n",
    "    elif isinstance(obj, list):\n",
    "        data = obj\n",
    "    elif isinstance(obj, dict):\n",
    "        data = [obj]\n",
    "    else:\n",
    "        raise RuntimeError(\"ë£© JSON í˜•ì‹ ì˜¤ë¥˜\")\n",
    "    looks = [normalize_look(look) for look in data]\n",
    "    return [lk for lk in looks if lk[\"garment_urls\"]]\n",
    "\n",
    "# ---------- 403 ìš°íšŒ ë‹¤ìš´ë¡œë“œ ìœ í‹¸ ----------\n",
    "from urllib.parse import urlparse\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "def _make_session() -> requests.Session:\n",
    "    s = requests.Session()\n",
    "    retry = Retry(\n",
    "        total=3, backoff_factor=0.6,\n",
    "        status_forcelist=[403, 408, 429, 500, 502, 503, 504],\n",
    "        allowed_methods=[\"GET\", \"HEAD\"]\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry, pool_connections=20, pool_maxsize=20)\n",
    "    s.mount(\"http://\", adapter)\n",
    "    s.mount(\"https://\", adapter)\n",
    "    return s\n",
    "\n",
    "SESSION = _make_session()\n",
    "\n",
    "def _headers_for(url: str) -> Dict[str, str]:\n",
    "    o = urlparse(url)\n",
    "    referer = f\"{o.scheme}://{o.netloc}/\"\n",
    "    return {\n",
    "        \"User-Agent\": (\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                       \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                       \"Chrome/115.0 Safari/537.36\"),\n",
    "        \"Referer\": referer,\n",
    "        \"Accept\": \"image/avif,image/webp,image/apng,image/*,*/*;q=0.8\",\n",
    "        \"Accept-Language\": \"ko-KR,ko;q=0.9,en-US;q=0.8\",\n",
    "        \"Connection\": \"keep-alive\",\n",
    "    }\n",
    "\n",
    "def download_image(url: str, timeout: int = 30) -> Optional[Image.Image]:\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                      \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                      \"Chrome/120.0.0.0 Safari/537.36\",\n",
    "        \"Referer\": url.split(\"/web/\")[0],  # mullang.com ê°™ì€ ë„ë©”ì¸\n",
    "        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8\",\n",
    "    }\n",
    "    try:\n",
    "        r = requests.get(url, headers=headers, timeout=timeout)\n",
    "        r.raise_for_status()\n",
    "        return Image.open(io.BytesIO(r.content)).convert(\"RGB\")\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {url} ({e})\")\n",
    "        return None\n",
    "\n",
    "# ---------- Canny ë³€í™˜ ----------\n",
    "def make_canny_image(pil_img: Image.Image) -> Image.Image:\n",
    "    arr = np.array(pil_img.convert(\"RGB\"))\n",
    "    gray = cv2.cvtColor(arr, cv2.COLOR_RGB2GRAY)\n",
    "    edges = cv2.Canny(gray, 100, 200)\n",
    "    edges_rgb = cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)\n",
    "    return Image.fromarray(edges_rgb)\n",
    "\n",
    "# ---------- í”„ë¡¬í”„íŠ¸ ----------\n",
    "def build_prompt(garment_urls: List[str], look_style: Optional[str]) -> str:\n",
    "    refs = \", \".join(garment_urls)\n",
    "    style_hint = f\" Style: {look_style}.\" if look_style else \"\"\n",
    "    return (\n",
    "        \"A full-body photorealistic studio photo of a fashion model. \"\n",
    "        \"The model must be wearing these exact garments without alteration: \"\n",
    "        f\"{refs}.\"\n",
    "        f\"{style_hint} Natural face, realistic folds/shadows, minimal background.\"\n",
    "    )\n",
    "\n",
    "# ---------- ì´ë¯¸ì§€ ìƒì„± ----------\n",
    "async def generate_image(garment_urls: List[str], prompt: str) -> Optional[bytes]:\n",
    "    loop = asyncio.get_event_loop()\n",
    "    def _run():\n",
    "        # ì—¬ëŸ¬ ì¥ ì¤‘ ì ‘ê·¼ ê°€ëŠ¥í•œ ê²ƒë§Œ ìˆ˜ì§‘\n",
    "        imgs: List[Image.Image] = []\n",
    "        for u in garment_urls:\n",
    "            if not u:\n",
    "                continue\n",
    "            img = download_image(u)\n",
    "            if img is not None:\n",
    "                imgs.append(img)\n",
    "        if not imgs:\n",
    "            print(\"[ERROR] ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥í•œ ì˜ë¥˜ ì´ë¯¸ì§€ê°€ ì—†ìŒ\")\n",
    "            return None\n",
    "\n",
    "        # í˜„ì¬ëŠ” ì²« ì¥ë§Œ ControlNetì— ì‚¬ìš© (ì—¬ëŸ¬ ì¥ ë©€í‹° Controlì€ í™•ì¥ ê°€ëŠ¥)\n",
    "        control_img = make_canny_image(imgs[0])\n",
    "\n",
    "        result = pipe(\n",
    "            prompt=prompt,\n",
    "            image=control_img,\n",
    "            num_inference_steps=20,     # Colab T4 íƒ€í˜‘ê°’\n",
    "            guidance_scale=7.0,\n",
    "            width=SIZE_W,\n",
    "            height=SIZE_H,\n",
    "        ).images[0]\n",
    "\n",
    "        buf = io.BytesIO()\n",
    "        result.save(buf, format=\"PNG\")\n",
    "        buf.seek(0)\n",
    "        return buf.getvalue()\n",
    "    return await loop.run_in_executor(None, _run)\n",
    "\n",
    "# ---------- S3 ì—…ë¡œë” ----------\n",
    "def _sanitize_key_part(s: str) -> str:\n",
    "    s = s.strip().replace(\" \", \"_\")\n",
    "    return re.sub(r\"[^A-Za-z0-9._/-]+\", \"-\", s)\n",
    "\n",
    "class S3Uploader:\n",
    "    def __init__(self, bucket: str, region: str, prefix: str = \"tryon\"):\n",
    "        import boto3\n",
    "        self.bucket = bucket\n",
    "        self.region = region\n",
    "        self.prefix = (prefix or \"\").strip(\"/\")\n",
    "        self.s3 = boto3.client(\"s3\", region_name=region)\n",
    "\n",
    "    def put_bytes(self, data: bytes, key: str, content_type=\"image/png\") -> Dict[str,str]:\n",
    "        self.s3.put_object(\n",
    "            Bucket=self.bucket, Key=key, Body=data,\n",
    "            ContentType=content_type, ACL=\"public-read\"\n",
    "        )\n",
    "        return {\n",
    "            \"url\": f\"https://{self.bucket}.s3.{self.region}.amazonaws.com/{key}\"\n",
    "        }\n",
    "\n",
    "    def build_key(self, filename: str, look_id: str) -> str:\n",
    "        date = datetime.datetime.now(ZoneInfo(\"Asia/Seoul\")).strftime(\"%Y%m%d\")\n",
    "        safe_look = _sanitize_key_part(look_id)\n",
    "        safe_file = _sanitize_key_part(filename)\n",
    "        return f\"{self.prefix}/{date}/{safe_look}/{safe_file}\"\n",
    "\n",
    "# ---------- ì‹¤í–‰ ----------\n",
    "async def process_look(look, idx, uploader):\n",
    "    look_id = look[\"look_id\"]\n",
    "    garment_urls = look[\"garment_urls\"]\n",
    "    print(f\"[INFO] look#{idx} ({look_id}) ì‹œì‘\")\n",
    "    prompt = build_prompt(garment_urls, look[\"meta\"].get(\"look_style\"))\n",
    "\n",
    "    t0 = time.time()\n",
    "    img_bytes = await generate_image(garment_urls, prompt)\n",
    "    if not img_bytes:\n",
    "        print(f\"[ERROR] look#{idx} ({look_id}) ìƒì„± ì‹¤íŒ¨\")\n",
    "        return None\n",
    "\n",
    "    out_name = f\"look_{idx:03d}_{_sanitize_key_part(look_id)}.png\"\n",
    "    s3_key = uploader.build_key(out_name, look_id)\n",
    "    res = uploader.put_bytes(img_bytes, s3_key)\n",
    "    print(f\"[OK] {look_id} â†’ {res['url']}  (â± {time.time()-t0:.2f}s)\")\n",
    "    return res\n",
    "\n",
    "async def main_async():\n",
    "    looks = load_all_looks(LOOKS_JSON)[:5]\n",
    "    uploader = S3Uploader(AWS_S3_BUCKET, AWS_REGION, AWS_S3_PREFIX)\n",
    "    tasks = [process_look(look, idx, uploader) for idx, look in enumerate(looks, start=1)]\n",
    "    await asyncio.gather(*tasks)\n",
    "\n",
    "# â¬‡ï¸ Colab/Jupyter: asyncio.run() ì“°ì§€ ë§ê³  await\n",
    "start = time.time()\n",
    "await main_async()\n",
    "print(f\"ì´ ì†Œìš”ì‹œê°„: {time.time()-start:.2f} ì´ˆ\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 790,
     "referenced_widgets": [
      "f472292fd80447d7af11ca94fdbcbe06",
      "2092ff8bb7fd49638fdc156961ab96ac",
      "ddaa2f855b104cba9a4f029f77517cb3",
      "1a1fa2569fb14b2f925f62cecaffb131",
      "9d94d59f7b1e46fbb9c1811c0e605177",
      "20389200a9044d54b9c7a0c20532f74c",
      "d6a38ca85d6f4b168804c68e8c9d31c3",
      "5e68c7507d394d13ad0156cbf71fd856",
      "f92931dc3c124222ae71d4a81b4d30c0",
      "b696b5d2430b4d4e9b472dd8bfb2ec82",
      "be39f46d21d845338d2a630817a293cc",
      "77cf5572be36470e8639b7f9b3583010",
      "d9ff31f05fff4a42be53c469986b1bdc",
      "2f280d61a7bc477d943c9abec7dcb99f",
      "af13a6d2fdd447688c00a79857492544",
      "8e0a2454cf114a49b8813a9588864050",
      "39b8e289016745ef8ffb1bf334e6af74",
      "a1a223f15a0044ba8367212d5c6bee86",
      "7238d70d548f4a27b7e2759d822ba33b",
      "15f1e964ce6d4db4a59263c84c30b1ad",
      "0e3899acecf643ee9a12e0fde9be9152",
      "7f520ca6c0574f88ac8c27a7c740322a",
      "438626f27296461d9892896f90cfeca3",
      "2eaa8c3616ab466ba78c9463df75e782",
      "e891537e6a7943e7a70041a54fed850e",
      "9ffb8cff65304b02bf2eeec51f1dc6ff",
      "f0273d361f794d5eadba18bfb2e4d0f0",
      "4d7d643b2f7b42f291b737820ba0ec8b"
     ]
    },
    "id": "jNURxZsHgkmC",
    "executionInfo": {
     "status": "error",
     "timestamp": 1758097648640,
     "user_tz": -540,
     "elapsed": 73760,
     "user": {
      "displayName": "Jh K",
      "userId": "12877179054230177413"
     }
    },
    "outputId": "a1cafeab-62a8-469a-f43b-659df12dbfdb"
   },
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f472292fd80447d7af11ca94fdbcbe06"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a1a223f15a0044ba8367212d5c6bee86"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "You have disabled the safety checker for <class 'diffusers.pipelines.controlnet.pipeline_controlnet.StableDiffusionControlNetPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 4.12 MiB is free. Process 161252 has 14.73 GiB memory in use. Of the allocated memory 14.38 GiB is allocated by PyTorch, and 259.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOutOfMemoryError\u001B[0m                          Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipython-input-3808243808.py\u001B[0m in \u001B[0;36m<cell line: 0>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     49\u001B[0m     \u001B[0mtorch_dtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloat16\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mdevice\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"cuda\"\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloat32\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     50\u001B[0m     \u001B[0;31m# safety_checker=None  # âŒ ë°°í¬ìš© ì•„ë‹˜: ê¸°ë³¸ê°’ ìœ ì§€(ê²½ê³  ì•ˆ ëœ¨ê²Œ)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 51\u001B[0;31m ).to(device)\n\u001B[0m\u001B[1;32m     52\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     53\u001B[0m \u001B[0;31m# ---------- JSON â†’ ë£© ì •ê·œí™” ----------\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/diffusers/pipelines/pipeline_utils.py\u001B[0m in \u001B[0;36mto\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    452\u001B[0m                 \u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    453\u001B[0m             \u001B[0;32melif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mis_loaded_in_4bit_bnb\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mis_loaded_in_8bit_bnb\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 454\u001B[0;31m                 \u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    455\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    456\u001B[0m             if (\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/diffusers/models/modeling_utils.py\u001B[0m in \u001B[0;36mto\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1029\u001B[0m                     \u001B[0;34mf\"The current device is `{self.device}`. If you intended to move the model, please install bitsandbytes >= 0.43.2.\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1030\u001B[0m                 )\n\u001B[0;32m-> 1031\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1032\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1033\u001B[0m     \u001B[0;31m# Taken from `transformers`.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36mto\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1367\u001B[0m                     \u001B[0;32mraise\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1368\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1369\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconvert\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1370\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1371\u001B[0m     def register_full_backward_pre_hook(\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    926\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mrecurse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    927\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 928\u001B[0;31m                 \u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    929\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    930\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtensor_applied\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    926\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mrecurse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    927\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 928\u001B[0;31m                 \u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    929\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    930\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtensor_applied\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    926\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mrecurse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    927\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 928\u001B[0;31m                 \u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    929\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    930\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtensor_applied\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    926\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mrecurse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    927\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 928\u001B[0;31m                 \u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    929\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    930\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtensor_applied\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    926\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mrecurse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    927\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 928\u001B[0;31m                 \u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    929\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    930\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtensor_applied\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    926\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mrecurse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    927\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 928\u001B[0;31m                 \u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    929\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    930\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtensor_applied\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    926\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mrecurse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    927\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 928\u001B[0;31m                 \u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    929\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    930\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtensor_applied\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    926\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mrecurse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    927\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 928\u001B[0;31m                 \u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    929\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    930\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtensor_applied\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    926\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mrecurse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    927\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 928\u001B[0;31m                 \u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    929\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    930\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtensor_applied\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    953\u001B[0m             \u001B[0;31m# `with torch.no_grad():`\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    954\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mno_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 955\u001B[0;31m                 \u001B[0mparam_applied\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mparam\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    956\u001B[0m             \u001B[0mp_should_use_set_data\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mparam\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mparam_applied\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    957\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36mconvert\u001B[0;34m(t)\u001B[0m\n\u001B[1;32m   1353\u001B[0m                         \u001B[0mmemory_format\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mconvert_to_format\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1354\u001B[0m                     )\n\u001B[0;32m-> 1355\u001B[0;31m                 return t.to(\n\u001B[0m\u001B[1;32m   1356\u001B[0m                     \u001B[0mdevice\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1357\u001B[0m                     \u001B[0mdtype\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_floating_point\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_complex\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mOutOfMemoryError\u001B[0m: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 4.12 MiB is free. Process 161252 has 14.73 GiB memory in use. Of the allocated memory 14.38 GiB is allocated by PyTorch, and 259.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install diffusers==0.31.0 transformers accelerate safetensors boto3 opencv-python-headless"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ORlUM2WMk-IC",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1758095776053,
     "user_tz": -540,
     "elapsed": 11792,
     "user": {
      "displayName": "Jh K",
      "userId": "12877179054230177413"
     }
    },
    "outputId": "9cec9085-1c51-4173-8bf7-45197de49280"
   },
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting diffusers==0.31.0\n",
      "  Downloading diffusers-0.31.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.1)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (0.6.2)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.12/dist-packages (1.40.32)\n",
      "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.12/dist-packages (from diffusers==0.31.0) (8.7.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from diffusers==0.31.0) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.2 in /usr/local/lib/python3.12/dist-packages (from diffusers==0.31.0) (0.34.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from diffusers==0.31.0) (2.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from diffusers==0.31.0) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from diffusers==0.31.0) (2.32.4)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from diffusers==0.31.0) (11.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.8.0+cu126)\n",
      "Requirement already satisfied: botocore<1.41.0,>=1.40.32 in /usr/local/lib/python3.12/dist-packages (from boto3) (1.40.32)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.15.0,>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from boto3) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.12/dist-packages (from botocore<1.41.0,>=1.40.32->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.12/dist-packages (from botocore<1.41.0,>=1.40.32->boto3) (2.5.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.31.0) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.31.0) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.31.0) (1.1.9)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.4.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata->diffusers==0.31.0) (3.23.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers==0.31.0) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers==0.31.0) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers==0.31.0) (2025.8.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.41.0,>=1.40.32->boto3) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Downloading diffusers-0.31.0-py3-none-any.whl (2.9 MB)\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m2.9/2.9 MB\u001B[0m \u001B[31m41.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: diffusers\n",
      "  Attempting uninstall: diffusers\n",
      "    Found existing installation: diffusers 0.35.1\n",
      "    Uninstalling diffusers-0.35.1:\n",
      "      Successfully uninstalled diffusers-0.35.1\n",
      "Successfully installed diffusers-0.31.0\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "diffusers"
        ]
       },
       "id": "083f6fe35b924a4f8326e0e9426cac7e"
      }
     },
     "metadata": {}
    }
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "f472292fd80447d7af11ca94fdbcbe06": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "VBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2092ff8bb7fd49638fdc156961ab96ac",
       "IPY_MODEL_ddaa2f855b104cba9a4f029f77517cb3",
       "IPY_MODEL_1a1fa2569fb14b2f925f62cecaffb131",
       "IPY_MODEL_9d94d59f7b1e46fbb9c1811c0e605177",
       "IPY_MODEL_20389200a9044d54b9c7a0c20532f74c"
      ],
      "layout": "IPY_MODEL_d6a38ca85d6f4b168804c68e8c9d31c3"
     }
    },
    "2092ff8bb7fd49638fdc156961ab96ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5e68c7507d394d13ad0156cbf71fd856",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_f92931dc3c124222ae71d4a81b4d30c0",
      "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
     }
    },
    "ddaa2f855b104cba9a4f029f77517cb3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "PasswordModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "PasswordModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "PasswordView",
      "continuous_update": true,
      "description": "Token:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_b696b5d2430b4d4e9b472dd8bfb2ec82",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_be39f46d21d845338d2a630817a293cc",
      "value": ""
     }
    },
    "1a1fa2569fb14b2f925f62cecaffb131": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "CheckboxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "CheckboxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "CheckboxView",
      "description": "Add token as git credential?",
      "description_tooltip": null,
      "disabled": false,
      "indent": true,
      "layout": "IPY_MODEL_77cf5572be36470e8639b7f9b3583010",
      "style": "IPY_MODEL_d9ff31f05fff4a42be53c469986b1bdc",
      "value": true
     }
    },
    "9d94d59f7b1e46fbb9c1811c0e605177": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ButtonModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Login",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_2f280d61a7bc477d943c9abec7dcb99f",
      "style": "IPY_MODEL_af13a6d2fdd447688c00a79857492544",
      "tooltip": ""
     }
    },
    "20389200a9044d54b9c7a0c20532f74c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8e0a2454cf114a49b8813a9588864050",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_39b8e289016745ef8ffb1bf334e6af74",
      "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
     }
    },
    "d6a38ca85d6f4b168804c68e8c9d31c3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": "center",
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "flex",
      "flex": null,
      "flex_flow": "column",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "50%"
     }
    },
    "5e68c7507d394d13ad0156cbf71fd856": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f92931dc3c124222ae71d4a81b4d30c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b696b5d2430b4d4e9b472dd8bfb2ec82": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "be39f46d21d845338d2a630817a293cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "77cf5572be36470e8639b7f9b3583010": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d9ff31f05fff4a42be53c469986b1bdc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2f280d61a7bc477d943c9abec7dcb99f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af13a6d2fdd447688c00a79857492544": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ButtonStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "8e0a2454cf114a49b8813a9588864050": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "39b8e289016745ef8ffb1bf334e6af74": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a1a223f15a0044ba8367212d5c6bee86": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7238d70d548f4a27b7e2759d822ba33b",
       "IPY_MODEL_15f1e964ce6d4db4a59263c84c30b1ad",
       "IPY_MODEL_0e3899acecf643ee9a12e0fde9be9152"
      ],
      "layout": "IPY_MODEL_7f520ca6c0574f88ac8c27a7c740322a"
     }
    },
    "7238d70d548f4a27b7e2759d822ba33b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_438626f27296461d9892896f90cfeca3",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_2eaa8c3616ab466ba78c9463df75e782",
      "value": "Loadingâ€‡pipelineâ€‡components...:â€‡100%"
     }
    },
    "15f1e964ce6d4db4a59263c84c30b1ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e891537e6a7943e7a70041a54fed850e",
      "max": 5,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9ffb8cff65304b02bf2eeec51f1dc6ff",
      "value": 5
     }
    },
    "0e3899acecf643ee9a12e0fde9be9152": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f0273d361f794d5eadba18bfb2e4d0f0",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_4d7d643b2f7b42f291b737820ba0ec8b",
      "value": "â€‡5/5â€‡[01:03&lt;00:00,â€‡13.31s/it]"
     }
    },
    "7f520ca6c0574f88ac8c27a7c740322a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "438626f27296461d9892896f90cfeca3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2eaa8c3616ab466ba78c9463df75e782": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e891537e6a7943e7a70041a54fed850e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ffb8cff65304b02bf2eeec51f1dc6ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f0273d361f794d5eadba18bfb2e4d0f0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d7d643b2f7b42f291b737820ba0ec8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
