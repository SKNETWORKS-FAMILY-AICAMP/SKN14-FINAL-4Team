{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 17090,
     "status": "ok",
     "timestamp": 1756969626055,
     "user": {
      "displayName": "sr c",
      "userId": "02365314278665536029"
     },
     "user_tz": -540
    },
    "id": "RPJ-VYz-S9fZ",
    "outputId": "a33666c4-07b0-4dd4-c084-bfcba6bc501a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
      "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.101.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.192-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.40.23-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Downloading ultralytics_thop-2.0.17-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
      "Collecting botocore<1.41.0,>=1.40.23 (from boto3)\n",
      "  Downloading botocore-1.40.23-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.14.0,>=0.13.0 (from boto3)\n",
      "  Downloading s3transfer-0.13.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.12/dist-packages (from botocore<1.41.0,>=1.40.23->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.59.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.41.0,>=1.40.23->boto3) (1.17.0)\n",
      "Downloading ultralytics-8.3.192-py3-none-any.whl (1.1 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.1/1.1 MB\u001B[0m \u001B[31m28.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading boto3-1.40.23-py3-none-any.whl (139 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m139.3/139.3 kB\u001B[0m \u001B[31m11.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading botocore-1.40.23-py3-none-any.whl (14.0 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m14.0/14.0 MB\u001B[0m \u001B[31m90.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading s3transfer-0.13.1-py3-none-any.whl (85 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m85.3/85.3 kB\u001B[0m \u001B[31m7.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading ultralytics_thop-2.0.17-py3-none-any.whl (28 kB)\n",
      "Installing collected packages: jmespath, botocore, s3transfer, ultralytics-thop, boto3, ultralytics\n",
      "Successfully installed boto3-1.40.23 botocore-1.40.23 jmespath-1.0.1 s3transfer-0.13.1 ultralytics-8.3.192 ultralytics-thop-2.0.17\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow requests openai tqdm ultralytics torch torchvision torchaudio boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L9ixJrDQbmTH"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from google.colab import userdata\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY_PJ\")\n",
    "os.environ[\"AWS_S3_BUCKET_NAME\"] = userdata.get(\"AWS_S3_BUCKET_NAME\")\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = userdata.get(\"AWS_ACCESS_KEY_ID\")\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = userdata.get(\"AWS_SECRET_ACCESS_KEY\")\n",
    "os.environ[\"AWS_REGION\"] = \"ap-northeast-2\"\n",
    "os.environ[\"S3_FOLDER_PREFIX\"] = \"model_img\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 55,
     "status": "ok",
     "timestamp": 1756970428094,
     "user": {
      "displayName": "sr c",
      "userId": "02365314278665536029"
     },
     "user_tz": -540
    },
    "id": "hWoC-OhfW47W",
    "outputId": "a907a36b-81f9-402b-d114-c5f31b026709"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ s3_uploader.py 모듈이 생성되었습니다.\n"
     ]
    }
   ],
   "source": [
    "s3_uploader_code = '''\n",
    "\"\"\"\n",
    "s3_uploader.py\n",
    "Virtual Try-on 결과 이미지를 S3에 업로드하고 URL을 반환하는 모듈\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import io\n",
    "import boto3\n",
    "from pathlib import Path\n",
    "from typing import Optional, Union\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "from botocore.exceptions import ClientError, NoCredentialsError\n",
    "\n",
    "\n",
    "class S3ImageUploader:\n",
    "    \"\"\"S3에 이미지를 업로드하고 URL을 관리하는 클래스\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        bucket_name: str,\n",
    "        aws_access_key_id: Optional[str] = None,\n",
    "        aws_secret_access_key: Optional[str] = None,\n",
    "        region_name: str = 'ap-northeast-2',\n",
    "        folder_prefix: str = 'tryon-images'\n",
    "    ):\n",
    "        \"\"\"S3 업로더 초기화\"\"\"\n",
    "        self.bucket_name = bucket_name\n",
    "        self.folder_prefix = folder_prefix.strip('/')\n",
    "\n",
    "        try:\n",
    "            if aws_access_key_id and aws_secret_access_key:\n",
    "                self.s3_client = boto3.client(\n",
    "                    's3',\n",
    "                    aws_access_key_id=aws_access_key_id,\n",
    "                    aws_secret_access_key=aws_secret_access_key,\n",
    "                    region_name=region_name\n",
    "                )\n",
    "            else:\n",
    "                self.s3_client = boto3.client('s3', region_name=region_name)\n",
    "\n",
    "            # 버킷 접근 권한 확인\n",
    "            self.s3_client.head_bucket(Bucket=bucket_name)\n",
    "\n",
    "        except NoCredentialsError:\n",
    "            raise ValueError(\"AWS 자격 증명을 찾을 수 없습니다.\")\n",
    "        except ClientError as e:\n",
    "            error_code = e.response['Error']['Code']\n",
    "            if error_code == '403':\n",
    "                raise ValueError(f\"S3 버킷 '{bucket_name}'에 대한 액세스 권한이 없습니다.\")\n",
    "            elif error_code == '404':\n",
    "                raise ValueError(f\"S3 버킷 '{bucket_name}'을 찾을 수 없습니다.\")\n",
    "            else:\n",
    "                raise ValueError(f\"S3 연결 오류: {e}\")\n",
    "\n",
    "    def _generate_filename(self, product_id: str, extension: str = 'png') -> str:\n",
    "        \"\"\"고유한 파일명 생성\"\"\"\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        unique_id = str(uuid.uuid4())[:8]\n",
    "        return f\"{self.folder_prefix}/{timestamp}/{product_id}_{unique_id}.{extension}\"\n",
    "\n",
    "    def upload_file(self, file_path: Union[str, Path], product_id: str) -> str:\n",
    "        \"\"\"\n",
    "        로컬 파일을 S3에 업로드하고 공개 URL 반환\n",
    "\n",
    "        Args:\n",
    "            file_path: 업로드할 파일 경로\n",
    "            product_id: 제품 ID\n",
    "\n",
    "        Returns:\n",
    "            S3 공개 URL\n",
    "        \"\"\"\n",
    "        file_path = Path(file_path)\n",
    "        if not file_path.exists():\n",
    "            raise FileNotFoundError(f\"파일을 찾을 수 없습니다: {file_path}\")\n",
    "\n",
    "        extension = file_path.suffix.lstrip('.')\n",
    "        s3_key = self._generate_filename(product_id, extension)\n",
    "\n",
    "        try:\n",
    "            self.s3_client.upload_file(\n",
    "                str(file_path),\n",
    "                self.bucket_name,\n",
    "                s3_key,\n",
    "                ExtraArgs={\n",
    "                    'ContentType': 'image/png' if extension.lower() == 'png' else 'image/jpeg',\n",
    "                    'ACL': 'public-read'\n",
    "                }\n",
    "            )\n",
    "\n",
    "            return f\"https://{self.bucket_name}.s3.amazonaws.com/{s3_key}\"\n",
    "\n",
    "        except ClientError as e:\n",
    "            raise RuntimeError(f\"S3 업로드 실패: {e}\")\n",
    "\n",
    "\n",
    "def setup_s3_uploader() -> S3ImageUploader:\n",
    "    \"\"\"환경변수에서 설정을 읽어 S3 업로더 생성\"\"\"\n",
    "    bucket_name = os.getenv('AWS_S3_BUCKET_NAME')\n",
    "    if not bucket_name:\n",
    "        raise ValueError(\"환경변수 AWS_S3_BUCKET_NAME이 설정되지 않았습니다.\")\n",
    "\n",
    "    return S3ImageUploader(\n",
    "        bucket_name=bucket_name,\n",
    "        aws_access_key_id=os.getenv('AWS_ACCESS_KEY_ID'),\n",
    "        aws_secret_access_key=os.getenv('AWS_SECRET_ACCESS_KEY'),\n",
    "        region_name=os.getenv('AWS_REGION', 'ap-northeast-2'),\n",
    "        folder_prefix=os.getenv('S3_FOLDER_PREFIX', 'tryon-results')\n",
    "    )\n",
    "'''\n",
    "\n",
    "# 파일로 저장\n",
    "with open('s3_uploader.py', 'w', encoding='utf-8') as f:\n",
    "    f.write(s3_uploader_code)\n",
    "\n",
    "print(\"✅ s3_uploader.py 모듈이 생성되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 419,
     "status": "ok",
     "timestamp": 1756970645171,
     "user": {
      "displayName": "sr c",
      "userId": "02365314278665536029"
     },
     "user_tz": -540
    },
    "id": "6gqgm1f_W47W",
    "outputId": "3ec27621-5001-41b7-f346-34824e40d4f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ S3 업로더 초기화 완료\n",
      "   버킷: elasticbeanstalk-ap-northeast-2-967883357924\n",
      "   폴더: model_img\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from openai import OpenAI\n",
    "\n",
    "# Python 경로에 현재 디렉토리 추가\n",
    "if '.' not in sys.path:\n",
    "    sys.path.append('.')\n",
    "\n",
    "# 기존 모듈 캐시 삭제\n",
    "if 's3_uploader' in sys.modules:\n",
    "    del sys.modules['s3_uploader']\n",
    "\n",
    "# ========= 사용자 설정 =========\n",
    "APP_JSON    = Path(\"app_product.json\")   # 제품 리스트\n",
    "OUT_DIR     = Path(\"out/tryon_openai\")\n",
    "MODEL_NAME  = \"gpt-image-1\"              # OpenAI 이미지 편집 모델\n",
    "\n",
    "# 이번 실행에서 처리할 id들\n",
    "SELECTED_IDS = [641]\n",
    "\n",
    "# 캔버스(좌: 모델 / 우: 의류 참고)\n",
    "SIZE      = (1536, 1024)   # (W, H)\n",
    "LEFT_BOX  = (0, 0, 768, 1024)\n",
    "RIGHT_BOX = (768, 0, 1536, 1024)\n",
    "\n",
    "# 카테고리별 기본 마스크 비율(LEFT_BOX 기준)\n",
    "CATEGORY_MASK_RATIOS = {\n",
    "    \"upper\":     (0.18, 0.18, 0.82, 0.64),\n",
    "    \"lower\":     (0.22, 0.55, 0.78, 0.95),\n",
    "    \"outer\":     (0.12, 0.12, 0.88, 0.85),\n",
    "    \"onepiece\":  (0.18, 0.18, 0.82, 0.90),\n",
    "    \"full\":      (0.10, 0.06, 0.90, 0.95),\n",
    "}\n",
    "MASK_FEATHER = 16\n",
    "\n",
    "# 로컬 GPU로 자동 마스크(세그멘테이션+포즈) 사용\n",
    "USE_LOCAL_GPU_MASK = True\n",
    "USE_POSE_LANDMARKS = True\n",
    "YOLO_SEG_MODEL     = \"yolov8n-seg.pt\"\n",
    "YOLO_POSE_MODEL    = \"yolov8n-pose.pt\"\n",
    "MIN_CONF_KEYPT     = 0.35\n",
    "\n",
    "# S3 업로드 설정\n",
    "USE_S3_UPLOAD = True\n",
    "\n",
    "# OpenAI 클라이언트 초기화\n",
    "client = OpenAI()\n",
    "\n",
    "# S3 업로더 초기화\n",
    "s3_uploader = None\n",
    "if USE_S3_UPLOAD:\n",
    "    try:\n",
    "        from s3_uploader import setup_s3_uploader\n",
    "        s3_uploader = setup_s3_uploader()\n",
    "        print(f\"✅ S3 업로더 초기화 완료\")\n",
    "        print(f\"   버킷: {s3_uploader.bucket_name}\")\n",
    "        print(f\"   폴더: {s3_uploader.folder_prefix}\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ S3 업로더 초기화 실패: {e}\")\n",
    "        USE_S3_UPLOAD = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "executionInfo": {
     "elapsed": 57,
     "status": "error",
     "timestamp": 1758096075638,
     "user": {
      "displayName": "Jh K",
      "userId": "12877179054230177413"
     },
     "user_tz": -540
    },
    "id": "ROe66uDrMHyi",
    "outputId": "55386a74-81f4-4a50-dfb6-03789d2092d7"
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "환경변수 OPENAI_API_KEY 필요",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipython-input-3203520146.py\u001B[0m in \u001B[0;36m<cell line: 0>\u001B[0;34m()\u001B[0m\n\u001B[1;32m    365\u001B[0m \u001B[0;31m# =============================================================================\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    366\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0m__name__\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"__main__\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 367\u001B[0;31m     \u001B[0mmain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/tmp/ipython-input-3203520146.py\u001B[0m in \u001B[0;36mmain\u001B[0;34m()\u001B[0m\n\u001B[1;32m    316\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mmain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    317\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgetenv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"OPENAI_API_KEY\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 318\u001B[0;31m         \u001B[0;32mraise\u001B[0m \u001B[0mRuntimeError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"환경변수 OPENAI_API_KEY 필요\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    319\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    320\u001B[0m     \u001B[0;31m# GPU 도구 확인(없으면 자동 비활성화)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: 환경변수 OPENAI_API_KEY 필요"
     ]
    }
   ],
   "source": [
    "# file: tryon_ids_openai.py\n",
    "import base64\n",
    "from pathlib import Path\n",
    "from typing import List, Any, Optional\n",
    "from PIL import Image, ImageOps, ImageDraw, ImageChops\n",
    "from openai import OpenAI\n",
    "from datetime import datetime\n",
    "\n",
    "def ensure_list(x):\n",
    "    if x is None: return []\n",
    "    return x if isinstance(x, list) else [x]\n",
    "\n",
    "def download_image(url: str) -> Image.Image:\n",
    "    r = requests.get(url, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    return Image.open(io.BytesIO(r.content)).convert(\"RGBA\")\n",
    "\n",
    "def download_bytes(url: str) -> bytes:\n",
    "    r = requests.get(url, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    return r.content\n",
    "\n",
    "def fit_into(img: Image.Image, box: tuple, keep_aspect=True, pad_color=(255,255,255,0)) -> Image.Image:\n",
    "    x1,y1,x2,y2 = box\n",
    "    w, h = x2-x1, y2-y1\n",
    "    if keep_aspect:\n",
    "        img = ImageOps.contain(img, (w,h))\n",
    "        canvas = Image.new(\"RGBA\", (w,h), pad_color)\n",
    "        canvas.paste(img, ((w - img.width)//2, (h - img.height)//2), img)\n",
    "        return canvas\n",
    "    return img.resize((w,h), Image.LANCZOS)\n",
    "\n",
    "def make_collage(model_img: Image.Image, garments: List[Image.Image]) -> Image.Image:\n",
    "    W,H = SIZE\n",
    "    canvas = Image.new(\"RGBA\", (W,H), (255,255,255,255))\n",
    "    left_fitted = fit_into(model_img, LEFT_BOX)\n",
    "    canvas.paste(left_fitted, (LEFT_BOX[0], LEFT_BOX[1]), left_fitted)\n",
    "\n",
    "    rows = max(1, min(2, len(garments)))\n",
    "    each_h = (RIGHT_BOX[3] - RIGHT_BOX[1]) // rows\n",
    "    for i, g in enumerate(garments[:rows], 0):\n",
    "        slot = (RIGHT_BOX[0], RIGHT_BOX[1] + i*each_h, RIGHT_BOX[2], RIGHT_BOX[1] + (i+1)*each_h)\n",
    "        fitted = fit_into(g, slot)\n",
    "        canvas.paste(fitted, (slot[0], slot[1]), fitted)\n",
    "    return canvas\n",
    "\n",
    "def _feather(mask: Image.Image, radius: int) -> Image.Image:\n",
    "    if radius <= 0: return mask\n",
    "    small = mask.resize((max(1,mask.width//4), max(1,mask.height//4)), Image.BILINEAR)\n",
    "    return small.resize(mask.size, Image.BILINEAR)\n",
    "\n",
    "# =============================================================================\n",
    "# 6. GPU 마스크 및 포즈 관련 함수들\n",
    "# =============================================================================\n",
    "def _person_mask_yolov8(model_img_rgba: Image.Image) -> Optional[Image.Image]:\n",
    "    try:\n",
    "        from ultralytics import YOLO\n",
    "        import torch\n",
    "    except Exception:\n",
    "        return None\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = YOLO(YOLO_SEG_MODEL)\n",
    "    crop = model_img_rgba.crop(LEFT_BOX).convert(\"RGB\")\n",
    "    results = model.predict(crop, imgsz=768, conf=0.25, device=device, verbose=False)\n",
    "    if not results or len(results[0].masks or []) == 0:\n",
    "        return None\n",
    "    import numpy as np\n",
    "    m = Image.new(\"L\", crop.size, 0)\n",
    "    for j, cls in enumerate(results[0].boxes.cls.tolist()):\n",
    "        if int(cls) == 0 and results[0].masks is not None:  # person class\n",
    "            mask_arr = results[0].masks.data[j].cpu().numpy()\n",
    "            mask_img = Image.fromarray((mask_arr*255).astype(\"uint8\"), mode=\"L\")\n",
    "            m = ImageChops.lighter(m, mask_img)\n",
    "    full = Image.new(\"L\", SIZE, 0)\n",
    "    full.paste(m, (LEFT_BOX[0], LEFT_BOX[1]))\n",
    "    return full\n",
    "\n",
    "def _pose_keypoints_yolo(model_img_rgba: Image.Image) -> Optional[dict]:\n",
    "    try:\n",
    "        from ultralytics import YOLO\n",
    "        import torch, numpy as np\n",
    "    except Exception:\n",
    "        return None\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    crop = model_img_rgba.crop(LEFT_BOX).convert(\"RGB\")\n",
    "    model = YOLO(YOLO_POSE_MODEL)\n",
    "    res = model.predict(crop, imgsz=768, device=device, conf=0.25, verbose=False)\n",
    "    if not res:\n",
    "        return None\n",
    "    r = res[0]\n",
    "    if r.keypoints is None or r.boxes is None or len(r.keypoints) == 0:\n",
    "        return None\n",
    "\n",
    "    areas = (r.boxes.xyxy[:,2]-r.boxes.xyxy[:,0]) * (r.boxes.xyxy[:,3]-r.boxes.xyxy[:,1])\n",
    "    idx = int((areas).argmax())\n",
    "    kpts = r.keypoints.xy[idx].cpu().numpy()  # (17,2)\n",
    "    conf = r.keypoints.conf[idx].cpu().numpy() if r.keypoints.conf is not None else __import__(\"numpy\").ones((kpts.shape[0],))\n",
    "\n",
    "    KP = {\"L_SHOULDER\":5,\"R_SHOULDER\":6,\"L_HIP\":11,\"R_HIP\":12,\"L_KNEE\":13,\"R_KNEE\":14,\"L_ANKLE\":15,\"R_ANKLE\":16}\n",
    "    def y_of(a,b):\n",
    "        ys=[]\n",
    "        for i in (a,b):\n",
    "            if i < len(kpts) and conf[i] >= MIN_CONF_KEYPT: ys.append(kpts[i][1])\n",
    "        return int(__import__(\"numpy\").mean(ys)) if ys else None\n",
    "\n",
    "    y_sh = y_of(KP[\"L_SHOULDER\"], KP[\"R_SHOULDER\"])\n",
    "    y_hp = y_of(KP[\"L_HIP\"],      KP[\"R_HIP\"])\n",
    "    y_kn = y_of(KP[\"L_KNEE\"],     KP[\"R_KNEE\"])\n",
    "    y_an = y_of(KP[\"L_ANKLE\"],    KP[\"R_ANKLE\"])\n",
    "\n",
    "    x1,y1,x2,y2 = r.boxes.xyxy[idx].cpu().numpy().astype(int).tolist()\n",
    "    x1 += LEFT_BOX[0]; x2 += LEFT_BOX[0]\n",
    "    y1 += LEFT_BOX[1]; y2 += LEFT_BOX[1]\n",
    "\n",
    "    def to_full_y(y): return int(y + LEFT_BOX[1]) if y is not None else None\n",
    "    return {\"shoulders_y\":to_full_y(y_sh),\"hips_y\":to_full_y(y_hp),\"knees_y\":to_full_y(y_kn),\"ankles_y\":to_full_y(y_an),\"bbox\":(x1,y1,x2,y2)}\n",
    "\n",
    "def make_mask(category: str, base_img: Image.Image) -> Image.Image:\n",
    "    mask = Image.new(\"L\", SIZE, 0)\n",
    "    draw = ImageDraw.Draw(mask)\n",
    "\n",
    "    dyn = _pose_keypoints_yolo(base_img) if USE_POSE_LANDMARKS else None\n",
    "    def rect(x1,y1,x2,y2): draw.rectangle((int(x1),int(y1),int(x2),int(y2)), fill=255)\n",
    "\n",
    "    if dyn:\n",
    "        x1,y1,x2,y2 = dyn[\"bbox\"]\n",
    "        pad_x = int((x2-x1)*0.08); pad_y = int((y2-y1)*0.05)\n",
    "        sh = dyn[\"shoulders_y\"] or (LEFT_BOX[1] + int((LEFT_BOX[3]-LEFT_BOX[1])*0.22))\n",
    "        hp = dyn[\"hips_y\"]      or (LEFT_BOX[1] + int((LEFT_BOX[3]-LEFT_BOX[1])*0.58))\n",
    "        kn = dyn[\"knees_y\"]     or (LEFT_BOX[1] + int((LEFT_BOX[3]-LEFT_BOX[1])*0.80))\n",
    "        an = dyn[\"ankles_y\"]    or (LEFT_BOX[1] + int((LEFT_BOX[3]-LEFT_BOX[1])*0.95))\n",
    "\n",
    "        cat = (category or \"upper\").lower()\n",
    "        if cat == \"upper\":\n",
    "            rect(max(LEFT_BOX[0], x1+pad_x), max(LEFT_BOX[1], sh - (hp-sh)*0.2),\n",
    "                 min(LEFT_BOX[2], x2-pad_x), min(LEFT_BOX[3], hp + (hp-sh)*0.05))\n",
    "        elif cat == \"lower\":\n",
    "            rect(max(LEFT_BOX[0], x1+pad_x), max(LEFT_BOX[1], hp - (hp-sh)*0.05),\n",
    "                 min(LEFT_BOX[2], x2-pad_x), min(LEFT_BOX[3], an))\n",
    "        elif cat == \"outer\":\n",
    "            rect(max(LEFT_BOX[0], x1+int(pad_x*0.7)), max(LEFT_BOX[1], sh - (hp-sh)*0.6),\n",
    "                 min(LEFT_BOX[2], x2-int(pad_x*0.7)), min(LEFT_BOX[3], kn))\n",
    "        elif cat in (\"onepiece\",\"dress\"):\n",
    "            rect(max(LEFT_BOX[0], x1+pad_x), max(LEFT_BOX[1], sh - (hp-sh)*0.2),\n",
    "                 min(LEFT_BOX[2], x2-pad_x), min(LEFT_BOX[3], max(kn, hp + (hp-sh))))\n",
    "        else:  # full\n",
    "            rect(max(LEFT_BOX[0], x1+pad_x), max(LEFT_BOX[1], y1+pad_y),\n",
    "                 min(LEFT_BOX[2], x2-pad_x), min(LEFT_BOX[3], an))\n",
    "    else:\n",
    "        rx1,ry1,rx2,ry2 = CATEGORY_MASK_RATIOS.get((category or \"upper\").lower(), CATEGORY_MASK_RATIOS[\"upper\"])\n",
    "        lx1,ly1,lx2,ly2 = LEFT_BOX\n",
    "        rect(lx1 + (lx2-lx1)*rx1, ly1 + (ly2-ly1)*ry1, lx1 + (lx2-lx1)*rx2, ly1 + (ly2-ly1)*ry2)\n",
    "\n",
    "    if USE_LOCAL_GPU_MASK:\n",
    "        person = _person_mask_yolov8(base_img)\n",
    "        if person is not None:\n",
    "            mask = ImageChops.multiply(mask, person)\n",
    "\n",
    "    return _feather(mask, MASK_FEATHER)\n",
    "\n",
    "# =============================================================================\n",
    "# 7. OpenAI 이미지 편집 + S3 업로드 함수\n",
    "# =============================================================================\n",
    "def call_openai_edit(base_img, mask_img, prompt, out_path):\n",
    "    \"\"\"OpenAI 이미지 편집 + S3 업로드\"\"\"\n",
    "    # 1) 마스크를 RGBA로 만들고, 알파 채널에 마스크를 복사\n",
    "    mask_L = mask_img.convert(\"L\")\n",
    "    mask_rgba = mask_L.convert(\"RGBA\")\n",
    "    mask_rgba.putalpha(mask_L)\n",
    "\n",
    "    # 2) BytesIO에 저장 + name 부여\n",
    "    base_buf = io.BytesIO()\n",
    "    base_img.save(base_buf, format=\"PNG\")\n",
    "    base_buf.seek(0)\n",
    "    base_buf.name = \"base.png\"\n",
    "\n",
    "    mask_buf = io.BytesIO()\n",
    "    mask_rgba.save(mask_buf, format=\"PNG\")\n",
    "    mask_buf.seek(0)\n",
    "    mask_buf.name = \"mask.png\"\n",
    "\n",
    "    # 3) OpenAI API 호출\n",
    "    resp = client.images.edit(\n",
    "        model=MODEL_NAME,\n",
    "        image=base_buf,\n",
    "        mask=mask_buf,\n",
    "        prompt=prompt,\n",
    "        size=\"1024x1024\",\n",
    "        n=1,\n",
    "    )\n",
    "\n",
    "    # 4) 로컬 저장\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    b64 = resp.data[0].b64_json\n",
    "    out_path.write_bytes(base64.b64decode(b64))\n",
    "    print(f\"💾 로컬 저장 완료: {out_path}\")\n",
    "\n",
    "    # 5) S3 업로드\n",
    "    if USE_S3_UPLOAD and s3_uploader:\n",
    "        try:\n",
    "            product_id = out_path.stem.split('_')[0]\n",
    "            s3_url = s3_uploader.upload_file(out_path, product_id)\n",
    "            print(f\"📤 S3 업로드 완료: {s3_url}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ S3 업로드 실패: {e}\")\n",
    "\n",
    "    return str(out_path)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 8. 모델 및 제품 데이터 로딩 함수들\n",
    "# =============================================================================\n",
    "def load_models_by_gender(path: Path) -> dict:\n",
    "    \"\"\"model_list.json을 로드해 성별별 대표 이미지 URL 딕셔너리로 정규화\"\"\"\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"모델 JSON 없음: {path}\")\n",
    "\n",
    "    raw = path.read_text(encoding=\"utf-8\").strip()\n",
    "    try:\n",
    "        obj = json.loads(raw)\n",
    "    except json.JSONDecodeError:\n",
    "        obj = [json.loads(l) for l in raw.splitlines() if l.strip()]\n",
    "\n",
    "    db = {}\n",
    "\n",
    "    def _norm_gender(g: str) -> str | None:\n",
    "        g = (g or \"\").strip().lower()\n",
    "        if g in (\"female\",\"f\",\"여\",\"여자\",\"woman\",\"girl\",\"w\"): return \"female\"\n",
    "        if g in (\"male\",\"m\",\"남\",\"남자\",\"man\",\"boy\"):         return \"male\"\n",
    "        if g in (\"default\",\"any\",\"*\"):                        return \"default\"\n",
    "        return None\n",
    "\n",
    "    def _extract_url(v) -> str | None:\n",
    "        if isinstance(v, dict):\n",
    "            return v.get(\"model_url\") or v.get(\"image_url\")\n",
    "        if isinstance(v, str):\n",
    "            return v\n",
    "        return None\n",
    "\n",
    "    if isinstance(obj, dict):\n",
    "        for g, v in obj.items():\n",
    "            key = _norm_gender(g)\n",
    "            url = _extract_url(v)\n",
    "            if key and url:\n",
    "                db[key] = url\n",
    "    else:\n",
    "        for it in obj:\n",
    "            key = _norm_gender(it.get(\"gender\"))\n",
    "            url = it.get(\"model_url\") or it.get(\"image_url\")\n",
    "            if key and url:\n",
    "                db[key] = url\n",
    "\n",
    "    return db\n",
    "\n",
    "def resolve_model_url_by_gender(item: dict, models_by_gender: dict) -> Optional[str]:\n",
    "    g = str(item.get(\"gender\") or item.get(\"model_gender\") or \"\").strip().lower()\n",
    "    key = \"female\" if g in (\"female\",\"f\",\"여\",\"여자\",\"woman\",\"girl\",\"w\") else \"male\" if g in (\"male\",\"m\",\"남\",\"남자\",\"man\",\"boy\") else None\n",
    "    if key and key in models_by_gender: return models_by_gender[key]\n",
    "    if \"default\" in models_by_gender:   return models_by_gender[\"default\"]\n",
    "    return models_by_gender.get(\"female\") or models_by_gender.get(\"male\")\n",
    "\n",
    "def load_items_by_ids(path: Path, selected_ids: List[Any]) -> List[dict]:\n",
    "    raw = path.read_text(encoding=\"utf-8\")\n",
    "    try:\n",
    "        data = json.loads(raw)\n",
    "        if isinstance(data, dict): data = [data]\n",
    "    except json.JSONDecodeError:\n",
    "        data = [json.loads(l) for l in raw.splitlines() if l.strip()]\n",
    "    sids = {str(x) for x in (selected_ids or [])}\n",
    "    picked = [it for it in data if str(it.get(\"id\") or it.get(\"external_id\")) in sids]\n",
    "    if not picked:\n",
    "        raise ValueError(f\"id {sorted(sids)} 항목을 찾지 못했습니다.\")\n",
    "    return picked\n",
    "\n",
    "# =============================================================================\n",
    "# 9. 결과 확인 함수들\n",
    "# =============================================================================\n",
    "def get_s3_urls_from_results(results_dir=\"out/tryon_openai\"):\n",
    "    \"\"\"생성된 결과에서 S3 URL들을 수집\"\"\"\n",
    "    results_dir = Path(results_dir)\n",
    "    s3_urls = {}\n",
    "\n",
    "    for info_file in results_dir.glob(\"*_info.json\"):\n",
    "        try:\n",
    "            data = json.loads(info_file.read_text())\n",
    "            product_id = data.get(\"product_id\")\n",
    "            s3_url = data.get(\"s3_url\")\n",
    "\n",
    "            if product_id and s3_url:\n",
    "                s3_urls[product_id] = {\n",
    "                    \"url\": s3_url,\n",
    "                    \"folder\": data.get(\"s3_folder\"),\n",
    "                    \"local_path\": data.get(\"local_path\"),\n",
    "                    \"timestamp\": data.get(\"timestamp\")\n",
    "                }\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return s3_urls\n",
    "\n",
    "\n",
    "def main():\n",
    "    if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "        raise RuntimeError(\"환경변수 OPENAI_API_KEY 필요\")\n",
    "\n",
    "    # GPU 도구 확인(없으면 자동 비활성화)\n",
    "    if USE_LOCAL_GPU_MASK or USE_POSE_LANDMARKS:\n",
    "        try:\n",
    "            import torch, ultralytics  # noqa\n",
    "        except Exception as e:\n",
    "            print(f\"[경고] 로컬 GPU 마스크/포즈 비활성화: {e}\")\n",
    "            globals()[\"USE_LOCAL_GPU_MASK\"] = False\n",
    "            globals()[\"USE_POSE_LANDMARKS\"] = False\n",
    "\n",
    "    # 제품 데이터 로드 (실제 URL은 무시)\n",
    "    items = load_items_by_ids(APP_JSON, SELECTED_IDS)\n",
    "    OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for item in items:\n",
    "        pid = item.get(\"id\") or item.get(\"external_id\")\n",
    "\n",
    "        # 실제 garment_urls 무시 → 더미 이미지 2개 생성\n",
    "        garments = []\n",
    "        for i, color in enumerate([\"red\", \"blue\"]):\n",
    "            g = Image.new(\"RGBA\", (512, 512), color=color)\n",
    "            garments.append(g)\n",
    "\n",
    "        # 모델 이미지도 더미 생성 (녹색)\n",
    "        model_img = Image.new(\"RGBA\", (512, 1024), color=\"green\")\n",
    "\n",
    "        # 콜라주 & 마스크\n",
    "        collage  = make_collage(model_img, garments)\n",
    "        category = str(item.get(\"category\") or \"upper\").lower()\n",
    "        mask_img = make_mask(category, collage)\n",
    "\n",
    "        # 프롬프트 (더미)\n",
    "        prompt = \"왼쪽 사람에 녹색 옷을 입히고 오른쪽 의류(빨강, 파랑)를 참조하여 착장처럼 보이게\"\n",
    "\n",
    "        # 생성 → 이미지 파일 저장 + S3 업로드\n",
    "        out_path = OUT_DIR / f\"{pid}_tryon.png\"\n",
    "        try:\n",
    "            saved = call_openai_edit(collage, mask_img, prompt, out_path)\n",
    "            print(f\"[OK] id={pid} → {saved}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] id={pid} 편집 실패: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 11. 실행\n",
    "# =============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# file: tryon_looks_sdxl_s3_colab.py\n",
    "import os, io, json, re, datetime, asyncio, time, requests\n",
    "from pathlib import Path\n",
    "from typing import List, Any, Dict, Optional\n",
    "from PIL import Image\n",
    "from zoneinfo import ZoneInfo\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import torch\n",
    "from diffusers import StableDiffusionControlNetPipeline, ControlNetModel\n",
    "import cv2, numpy as np\n",
    "\n",
    "# Colab/Jupyter 이벤트 루프 충돌 방지\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from huggingface_hub import login\n",
    "login(os.getenv(\"HF_TOKEN\"))  # 또는 직접 문자열 토큰 입력\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 환경변수\n",
    "# =========================\n",
    "SIZE_W, SIZE_H = 512, 512\n",
    "MAX_REFS = 6\n",
    "LOOKS_JSON = Path(os.getenv(\"LOOKS_JSON_PATH\", \"S3/app_product_test.json\"))\n",
    "\n",
    "AWS_S3_BUCKET  = os.getenv(\"AWS_S3_BUCKET_NAME\")\n",
    "AWS_REGION     = os.getenv(\"AWS_S3_REGION\", \"ap-northeast-2\")\n",
    "AWS_S3_PREFIX  = os.getenv(\"AWS_S3_PREFIX\", \"tryon\")\n",
    "\n",
    "# ===== 모델 조합 =====\n",
    "# HF 토큰으로 접근 승인 받은 SDXL base를 쓰려면 아래 라인 사용\n",
    "BASE_MODEL = \"stabilityai/stable-diffusion-xl-base-1.0\"   # (gated) 로그인 필요\n",
    "CONTROL_MODEL = \"lllyasviel/sd-controlnet-canny\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ===== 파이프라인 로드 (1회) =====\n",
    "controlnet = ControlNetModel.from_pretrained(\n",
    "    CONTROL_MODEL,\n",
    "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
    ")\n",
    "pipe = StableDiffusionControlNetPipeline.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    controlnet=controlnet,\n",
    "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
    "    # safety_checker=None  # ❌ 배포용 아님: 기본값 유지(경고 안 뜨게)\n",
    ").to(device)\n",
    "\n",
    "# ---------- JSON → 룩 정규화 ----------\n",
    "KNOWN_PART_KEYS = [\"top\",\"bottom\",\"outer\",\"onepiece\",\"dress\",\"bag\",\"shoes\",\"acc\",\"accessory\"]\n",
    "\n",
    "def normalize_look(look: Dict) -> Dict:\n",
    "    garment_urls: List[str] = []\n",
    "    ref_ids: List[str] = []\n",
    "    def add_part(part: Any):\n",
    "        if not isinstance(part, dict): return\n",
    "        url = part.get(\"image_url\")\n",
    "        pid = part.get(\"search_history_product_id\")\n",
    "        if url: garment_urls.append(url)\n",
    "        if pid is not None: ref_ids.append(str(pid))\n",
    "\n",
    "    for k in KNOWN_PART_KEYS:\n",
    "        if k in look:\n",
    "            v = look[k]\n",
    "            if isinstance(v, list):\n",
    "                for it in v: add_part(it)\n",
    "            else:\n",
    "                add_part(v)\n",
    "    raw_look_id = look.get(\"look_id\") or look.get(\"id\") or \"_\".join(ref_ids) or \"look\"\n",
    "    return {\n",
    "        \"look_id\": str(raw_look_id),\n",
    "        \"garment_urls\": garment_urls[:MAX_REFS],\n",
    "        \"ref_ids\": ref_ids,\n",
    "        \"meta\": {\"look_style\": look.get(\"look_style\")}\n",
    "    }\n",
    "\n",
    "def load_all_looks(path: Path) -> List[Dict]:\n",
    "    obj = json.loads(path.read_text(encoding=\"utf-8\"))\n",
    "    if isinstance(obj, dict) and isinstance(obj.get(\"results\"), list):\n",
    "        data = obj[\"results\"]\n",
    "    elif isinstance(obj, list):\n",
    "        data = obj\n",
    "    elif isinstance(obj, dict):\n",
    "        data = [obj]\n",
    "    else:\n",
    "        raise RuntimeError(\"룩 JSON 형식 오류\")\n",
    "    looks = [normalize_look(look) for look in data]\n",
    "    return [lk for lk in looks if lk[\"garment_urls\"]]\n",
    "\n",
    "# ---------- 403 우회 다운로드 유틸 ----------\n",
    "from urllib.parse import urlparse\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "def _make_session() -> requests.Session:\n",
    "    s = requests.Session()\n",
    "    retry = Retry(\n",
    "        total=3, backoff_factor=0.6,\n",
    "        status_forcelist=[403, 408, 429, 500, 502, 503, 504],\n",
    "        allowed_methods=[\"GET\", \"HEAD\"]\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry, pool_connections=20, pool_maxsize=20)\n",
    "    s.mount(\"http://\", adapter)\n",
    "    s.mount(\"https://\", adapter)\n",
    "    return s\n",
    "\n",
    "SESSION = _make_session()\n",
    "\n",
    "def _headers_for(url: str) -> Dict[str, str]:\n",
    "    o = urlparse(url)\n",
    "    referer = f\"{o.scheme}://{o.netloc}/\"\n",
    "    return {\n",
    "        \"User-Agent\": (\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                       \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                       \"Chrome/115.0 Safari/537.36\"),\n",
    "        \"Referer\": referer,\n",
    "        \"Accept\": \"image/avif,image/webp,image/apng,image/*,*/*;q=0.8\",\n",
    "        \"Accept-Language\": \"ko-KR,ko;q=0.9,en-US;q=0.8\",\n",
    "        \"Connection\": \"keep-alive\",\n",
    "    }\n",
    "\n",
    "def download_image(url: str, timeout: int = 30) -> Optional[Image.Image]:\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                      \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                      \"Chrome/120.0.0.0 Safari/537.36\",\n",
    "        \"Referer\": url.split(\"/web/\")[0],  # mullang.com 같은 도메인\n",
    "        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8\",\n",
    "    }\n",
    "    try:\n",
    "        r = requests.get(url, headers=headers, timeout=timeout)\n",
    "        r.raise_for_status()\n",
    "        return Image.open(io.BytesIO(r.content)).convert(\"RGB\")\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] 이미지 다운로드 실패: {url} ({e})\")\n",
    "        return None\n",
    "\n",
    "# ---------- Canny 변환 ----------\n",
    "def make_canny_image(pil_img: Image.Image) -> Image.Image:\n",
    "    arr = np.array(pil_img.convert(\"RGB\"))\n",
    "    gray = cv2.cvtColor(arr, cv2.COLOR_RGB2GRAY)\n",
    "    edges = cv2.Canny(gray, 100, 200)\n",
    "    edges_rgb = cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)\n",
    "    return Image.fromarray(edges_rgb)\n",
    "\n",
    "# ---------- 프롬프트 ----------\n",
    "def build_prompt(garment_urls: List[str], look_style: Optional[str]) -> str:\n",
    "    refs = \", \".join(garment_urls)\n",
    "    style_hint = f\" Style: {look_style}.\" if look_style else \"\"\n",
    "    return (\n",
    "        \"A full-body photorealistic studio photo of a fashion model. \"\n",
    "        \"The model must be wearing these exact garments without alteration: \"\n",
    "        f\"{refs}.\"\n",
    "        f\"{style_hint} Natural face, realistic folds/shadows, minimal background.\"\n",
    "    )\n",
    "\n",
    "# ---------- 이미지 생성 ----------\n",
    "async def generate_image(garment_urls: List[str], prompt: str) -> Optional[bytes]:\n",
    "    loop = asyncio.get_event_loop()\n",
    "    def _run():\n",
    "        # 여러 장 중 접근 가능한 것만 수집\n",
    "        imgs: List[Image.Image] = []\n",
    "        for u in garment_urls:\n",
    "            if not u:\n",
    "                continue\n",
    "            img = download_image(u)\n",
    "            if img is not None:\n",
    "                imgs.append(img)\n",
    "        if not imgs:\n",
    "            print(\"[ERROR] 다운로드 가능한 의류 이미지가 없음\")\n",
    "            return None\n",
    "\n",
    "        # 현재는 첫 장만 ControlNet에 사용 (여러 장 멀티 Control은 확장 가능)\n",
    "        control_img = make_canny_image(imgs[0])\n",
    "\n",
    "        result = pipe(\n",
    "            prompt=prompt,\n",
    "            image=control_img,\n",
    "            num_inference_steps=20,     # Colab T4 타협값\n",
    "            guidance_scale=7.0,\n",
    "            width=SIZE_W,\n",
    "            height=SIZE_H,\n",
    "        ).images[0]\n",
    "\n",
    "        buf = io.BytesIO()\n",
    "        result.save(buf, format=\"PNG\")\n",
    "        buf.seek(0)\n",
    "        return buf.getvalue()\n",
    "    return await loop.run_in_executor(None, _run)\n",
    "\n",
    "# ---------- S3 업로더 ----------\n",
    "def _sanitize_key_part(s: str) -> str:\n",
    "    s = s.strip().replace(\" \", \"_\")\n",
    "    return re.sub(r\"[^A-Za-z0-9._/-]+\", \"-\", s)\n",
    "\n",
    "class S3Uploader:\n",
    "    def __init__(self, bucket: str, region: str, prefix: str = \"tryon\"):\n",
    "        import boto3\n",
    "        self.bucket = bucket\n",
    "        self.region = region\n",
    "        self.prefix = (prefix or \"\").strip(\"/\")\n",
    "        self.s3 = boto3.client(\"s3\", region_name=region)\n",
    "\n",
    "    def put_bytes(self, data: bytes, key: str, content_type=\"image/png\") -> Dict[str,str]:\n",
    "        self.s3.put_object(\n",
    "            Bucket=self.bucket, Key=key, Body=data,\n",
    "            ContentType=content_type, ACL=\"public-read\"\n",
    "        )\n",
    "        return {\n",
    "            \"url\": f\"https://{self.bucket}.s3.{self.region}.amazonaws.com/{key}\"\n",
    "        }\n",
    "\n",
    "    def build_key(self, filename: str, look_id: str) -> str:\n",
    "        date = datetime.datetime.now(ZoneInfo(\"Asia/Seoul\")).strftime(\"%Y%m%d\")\n",
    "        safe_look = _sanitize_key_part(look_id)\n",
    "        safe_file = _sanitize_key_part(filename)\n",
    "        return f\"{self.prefix}/{date}/{safe_look}/{safe_file}\"\n",
    "\n",
    "# ---------- 실행 ----------\n",
    "async def process_look(look, idx, uploader):\n",
    "    look_id = look[\"look_id\"]\n",
    "    garment_urls = look[\"garment_urls\"]\n",
    "    print(f\"[INFO] look#{idx} ({look_id}) 시작\")\n",
    "    prompt = build_prompt(garment_urls, look[\"meta\"].get(\"look_style\"))\n",
    "\n",
    "    t0 = time.time()\n",
    "    img_bytes = await generate_image(garment_urls, prompt)\n",
    "    if not img_bytes:\n",
    "        print(f\"[ERROR] look#{idx} ({look_id}) 생성 실패\")\n",
    "        return None\n",
    "\n",
    "    out_name = f\"look_{idx:03d}_{_sanitize_key_part(look_id)}.png\"\n",
    "    s3_key = uploader.build_key(out_name, look_id)\n",
    "    res = uploader.put_bytes(img_bytes, s3_key)\n",
    "    print(f\"[OK] {look_id} → {res['url']}  (⏱ {time.time()-t0:.2f}s)\")\n",
    "    return res\n",
    "\n",
    "async def main_async():\n",
    "    looks = load_all_looks(LOOKS_JSON)[:5]\n",
    "    uploader = S3Uploader(AWS_S3_BUCKET, AWS_REGION, AWS_S3_PREFIX)\n",
    "    tasks = [process_look(look, idx, uploader) for idx, look in enumerate(looks, start=1)]\n",
    "    await asyncio.gather(*tasks)\n",
    "\n",
    "# ⬇️ Colab/Jupyter: asyncio.run() 쓰지 말고 await\n",
    "start = time.time()\n",
    "await main_async()\n",
    "print(f\"총 소요시간: {time.time()-start:.2f} 초\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 790,
     "referenced_widgets": [
      "f472292fd80447d7af11ca94fdbcbe06",
      "2092ff8bb7fd49638fdc156961ab96ac",
      "ddaa2f855b104cba9a4f029f77517cb3",
      "1a1fa2569fb14b2f925f62cecaffb131",
      "9d94d59f7b1e46fbb9c1811c0e605177",
      "20389200a9044d54b9c7a0c20532f74c",
      "d6a38ca85d6f4b168804c68e8c9d31c3",
      "5e68c7507d394d13ad0156cbf71fd856",
      "f92931dc3c124222ae71d4a81b4d30c0",
      "b696b5d2430b4d4e9b472dd8bfb2ec82",
      "be39f46d21d845338d2a630817a293cc",
      "77cf5572be36470e8639b7f9b3583010",
      "d9ff31f05fff4a42be53c469986b1bdc",
      "2f280d61a7bc477d943c9abec7dcb99f",
      "af13a6d2fdd447688c00a79857492544",
      "8e0a2454cf114a49b8813a9588864050",
      "39b8e289016745ef8ffb1bf334e6af74",
      "a1a223f15a0044ba8367212d5c6bee86",
      "7238d70d548f4a27b7e2759d822ba33b",
      "15f1e964ce6d4db4a59263c84c30b1ad",
      "0e3899acecf643ee9a12e0fde9be9152",
      "7f520ca6c0574f88ac8c27a7c740322a",
      "438626f27296461d9892896f90cfeca3",
      "2eaa8c3616ab466ba78c9463df75e782",
      "e891537e6a7943e7a70041a54fed850e",
      "9ffb8cff65304b02bf2eeec51f1dc6ff",
      "f0273d361f794d5eadba18bfb2e4d0f0",
      "4d7d643b2f7b42f291b737820ba0ec8b"
     ]
    },
    "id": "jNURxZsHgkmC",
    "executionInfo": {
     "status": "error",
     "timestamp": 1758097648640,
     "user_tz": -540,
     "elapsed": 73760,
     "user": {
      "displayName": "Jh K",
      "userId": "12877179054230177413"
     }
    },
    "outputId": "a1cafeab-62a8-469a-f43b-659df12dbfdb"
   },
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f472292fd80447d7af11ca94fdbcbe06"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a1a223f15a0044ba8367212d5c6bee86"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "You have disabled the safety checker for <class 'diffusers.pipelines.controlnet.pipeline_controlnet.StableDiffusionControlNetPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 4.12 MiB is free. Process 161252 has 14.73 GiB memory in use. Of the allocated memory 14.38 GiB is allocated by PyTorch, and 259.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOutOfMemoryError\u001B[0m                          Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipython-input-3808243808.py\u001B[0m in \u001B[0;36m<cell line: 0>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     49\u001B[0m     \u001B[0mtorch_dtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloat16\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mdevice\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"cuda\"\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloat32\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     50\u001B[0m     \u001B[0;31m# safety_checker=None  # ❌ 배포용 아님: 기본값 유지(경고 안 뜨게)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 51\u001B[0;31m ).to(device)\n\u001B[0m\u001B[1;32m     52\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     53\u001B[0m \u001B[0;31m# ---------- JSON → 룩 정규화 ----------\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/diffusers/pipelines/pipeline_utils.py\u001B[0m in \u001B[0;36mto\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    452\u001B[0m                 \u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    453\u001B[0m             \u001B[0;32melif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mis_loaded_in_4bit_bnb\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mis_loaded_in_8bit_bnb\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 454\u001B[0;31m                 \u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    455\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    456\u001B[0m             if (\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/diffusers/models/modeling_utils.py\u001B[0m in \u001B[0;36mto\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1029\u001B[0m                     \u001B[0;34mf\"The current device is `{self.device}`. If you intended to move the model, please install bitsandbytes >= 0.43.2.\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1030\u001B[0m                 )\n\u001B[0;32m-> 1031\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1032\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1033\u001B[0m     \u001B[0;31m# Taken from `transformers`.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36mto\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1367\u001B[0m                     \u001B[0;32mraise\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1368\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1369\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconvert\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1370\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1371\u001B[0m     def register_full_backward_pre_hook(\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    926\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mrecurse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    927\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 928\u001B[0;31m                 \u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    929\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    930\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtensor_applied\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    926\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mrecurse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    927\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 928\u001B[0;31m                 \u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    929\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    930\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtensor_applied\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    926\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mrecurse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    927\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 928\u001B[0;31m                 \u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    929\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    930\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtensor_applied\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    926\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mrecurse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    927\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 928\u001B[0;31m                 \u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    929\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    930\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtensor_applied\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    926\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mrecurse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    927\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 928\u001B[0;31m                 \u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    929\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    930\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtensor_applied\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    926\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mrecurse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    927\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 928\u001B[0;31m                 \u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    929\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    930\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtensor_applied\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    926\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mrecurse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    927\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 928\u001B[0;31m                 \u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    929\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    930\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtensor_applied\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    926\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mrecurse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    927\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 928\u001B[0;31m                 \u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    929\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    930\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtensor_applied\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    926\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mrecurse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    927\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 928\u001B[0;31m                 \u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    929\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    930\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtensor_applied\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    953\u001B[0m             \u001B[0;31m# `with torch.no_grad():`\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    954\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mno_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 955\u001B[0;31m                 \u001B[0mparam_applied\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mparam\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    956\u001B[0m             \u001B[0mp_should_use_set_data\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mparam\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mparam_applied\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    957\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36mconvert\u001B[0;34m(t)\u001B[0m\n\u001B[1;32m   1353\u001B[0m                         \u001B[0mmemory_format\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mconvert_to_format\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1354\u001B[0m                     )\n\u001B[0;32m-> 1355\u001B[0;31m                 return t.to(\n\u001B[0m\u001B[1;32m   1356\u001B[0m                     \u001B[0mdevice\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1357\u001B[0m                     \u001B[0mdtype\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_floating_point\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_complex\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mOutOfMemoryError\u001B[0m: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 4.12 MiB is free. Process 161252 has 14.73 GiB memory in use. Of the allocated memory 14.38 GiB is allocated by PyTorch, and 259.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install diffusers==0.31.0 transformers accelerate safetensors boto3 opencv-python-headless"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ORlUM2WMk-IC",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1758095776053,
     "user_tz": -540,
     "elapsed": 11792,
     "user": {
      "displayName": "Jh K",
      "userId": "12877179054230177413"
     }
    },
    "outputId": "9cec9085-1c51-4173-8bf7-45197de49280"
   },
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting diffusers==0.31.0\n",
      "  Downloading diffusers-0.31.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.1)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (0.6.2)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.12/dist-packages (1.40.32)\n",
      "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.12/dist-packages (from diffusers==0.31.0) (8.7.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from diffusers==0.31.0) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.2 in /usr/local/lib/python3.12/dist-packages (from diffusers==0.31.0) (0.34.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from diffusers==0.31.0) (2.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from diffusers==0.31.0) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from diffusers==0.31.0) (2.32.4)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from diffusers==0.31.0) (11.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.8.0+cu126)\n",
      "Requirement already satisfied: botocore<1.41.0,>=1.40.32 in /usr/local/lib/python3.12/dist-packages (from boto3) (1.40.32)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.15.0,>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from boto3) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.12/dist-packages (from botocore<1.41.0,>=1.40.32->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.12/dist-packages (from botocore<1.41.0,>=1.40.32->boto3) (2.5.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.31.0) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.31.0) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.31.0) (1.1.9)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.4.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata->diffusers==0.31.0) (3.23.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers==0.31.0) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers==0.31.0) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers==0.31.0) (2025.8.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.41.0,>=1.40.32->boto3) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Downloading diffusers-0.31.0-py3-none-any.whl (2.9 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.9/2.9 MB\u001B[0m \u001B[31m41.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: diffusers\n",
      "  Attempting uninstall: diffusers\n",
      "    Found existing installation: diffusers 0.35.1\n",
      "    Uninstalling diffusers-0.35.1:\n",
      "      Successfully uninstalled diffusers-0.35.1\n",
      "Successfully installed diffusers-0.31.0\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "diffusers"
        ]
       },
       "id": "083f6fe35b924a4f8326e0e9426cac7e"
      }
     },
     "metadata": {}
    }
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "f472292fd80447d7af11ca94fdbcbe06": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "VBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2092ff8bb7fd49638fdc156961ab96ac",
       "IPY_MODEL_ddaa2f855b104cba9a4f029f77517cb3",
       "IPY_MODEL_1a1fa2569fb14b2f925f62cecaffb131",
       "IPY_MODEL_9d94d59f7b1e46fbb9c1811c0e605177",
       "IPY_MODEL_20389200a9044d54b9c7a0c20532f74c"
      ],
      "layout": "IPY_MODEL_d6a38ca85d6f4b168804c68e8c9d31c3"
     }
    },
    "2092ff8bb7fd49638fdc156961ab96ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5e68c7507d394d13ad0156cbf71fd856",
      "placeholder": "​",
      "style": "IPY_MODEL_f92931dc3c124222ae71d4a81b4d30c0",
      "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
     }
    },
    "ddaa2f855b104cba9a4f029f77517cb3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "PasswordModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "PasswordModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "PasswordView",
      "continuous_update": true,
      "description": "Token:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_b696b5d2430b4d4e9b472dd8bfb2ec82",
      "placeholder": "​",
      "style": "IPY_MODEL_be39f46d21d845338d2a630817a293cc",
      "value": ""
     }
    },
    "1a1fa2569fb14b2f925f62cecaffb131": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "CheckboxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "CheckboxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "CheckboxView",
      "description": "Add token as git credential?",
      "description_tooltip": null,
      "disabled": false,
      "indent": true,
      "layout": "IPY_MODEL_77cf5572be36470e8639b7f9b3583010",
      "style": "IPY_MODEL_d9ff31f05fff4a42be53c469986b1bdc",
      "value": true
     }
    },
    "9d94d59f7b1e46fbb9c1811c0e605177": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ButtonModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Login",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_2f280d61a7bc477d943c9abec7dcb99f",
      "style": "IPY_MODEL_af13a6d2fdd447688c00a79857492544",
      "tooltip": ""
     }
    },
    "20389200a9044d54b9c7a0c20532f74c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8e0a2454cf114a49b8813a9588864050",
      "placeholder": "​",
      "style": "IPY_MODEL_39b8e289016745ef8ffb1bf334e6af74",
      "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
     }
    },
    "d6a38ca85d6f4b168804c68e8c9d31c3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": "center",
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "flex",
      "flex": null,
      "flex_flow": "column",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "50%"
     }
    },
    "5e68c7507d394d13ad0156cbf71fd856": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f92931dc3c124222ae71d4a81b4d30c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b696b5d2430b4d4e9b472dd8bfb2ec82": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "be39f46d21d845338d2a630817a293cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "77cf5572be36470e8639b7f9b3583010": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d9ff31f05fff4a42be53c469986b1bdc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2f280d61a7bc477d943c9abec7dcb99f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af13a6d2fdd447688c00a79857492544": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ButtonStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "8e0a2454cf114a49b8813a9588864050": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "39b8e289016745ef8ffb1bf334e6af74": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a1a223f15a0044ba8367212d5c6bee86": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7238d70d548f4a27b7e2759d822ba33b",
       "IPY_MODEL_15f1e964ce6d4db4a59263c84c30b1ad",
       "IPY_MODEL_0e3899acecf643ee9a12e0fde9be9152"
      ],
      "layout": "IPY_MODEL_7f520ca6c0574f88ac8c27a7c740322a"
     }
    },
    "7238d70d548f4a27b7e2759d822ba33b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_438626f27296461d9892896f90cfeca3",
      "placeholder": "​",
      "style": "IPY_MODEL_2eaa8c3616ab466ba78c9463df75e782",
      "value": "Loading pipeline components...: 100%"
     }
    },
    "15f1e964ce6d4db4a59263c84c30b1ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e891537e6a7943e7a70041a54fed850e",
      "max": 5,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9ffb8cff65304b02bf2eeec51f1dc6ff",
      "value": 5
     }
    },
    "0e3899acecf643ee9a12e0fde9be9152": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f0273d361f794d5eadba18bfb2e4d0f0",
      "placeholder": "​",
      "style": "IPY_MODEL_4d7d643b2f7b42f291b737820ba0ec8b",
      "value": " 5/5 [01:03&lt;00:00, 13.31s/it]"
     }
    },
    "7f520ca6c0574f88ac8c27a7c740322a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "438626f27296461d9892896f90cfeca3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2eaa8c3616ab466ba78c9463df75e782": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e891537e6a7943e7a70041a54fed850e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ffb8cff65304b02bf2eeec51f1dc6ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f0273d361f794d5eadba18bfb2e4d0f0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d7d643b2f7b42f291b737820ba0ec8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
